2019-05-23 01:35:07,577 CRIT Supervisor is running as root.  Privileges were not dropped because no user is specified in the config file.  If you intend to run as root, you can set user=root in the config file to avoid this message.
2019-05-23 01:35:07,580 INFO supervisord started with pid 1
2019-05-23 01:35:08,587 INFO spawned: 'app' with pid 8
2019-05-23 01:35:08,589 INFO spawned: 'app' with pid 9
2019-05-23 01:35:08,592 INFO spawned: 'mysqld' with pid 10
Downloading https://services.gradle.org/distributions/gradle-5.3-all.zip
.2019-05-23 01:35:10,387 INFO success: app entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
2019-05-23 01:35:10,388 INFO success: app entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
2019-05-23 01:35:10,389 INFO success: mysqld entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
.............................................................................................................................

Welcome to Gradle 5.3!

Here are the highlights of this release:
 - Feature variants AKA "optional dependencies"
 - Type-safe accessors in Kotlin precompiled script plugins
 - Gradle Module Metadata 1.0

For more details see https://docs.gradle.org/5.3/release-notes.html

Starting a Gradle Daemon (subsequent builds will be faster)
> Task :clean UP-TO-DATE
> Task :compileJava NO-SOURCE
> Task :compileScala
Pruning sources from previous analysis, due to incompatible CompileSetup.

> Task :compileScoverageJava NO-SOURCE

> Task :compileScoverageScala
Pruning sources from previous analysis, due to incompatible CompileSetup.

> Task :processResources NO-SOURCE
> Task :classes
> Task :compileTestJava NO-SOURCE

> Task :compileTestScala
Pruning sources from previous analysis, due to incompatible CompileSetup.
/apps/dataengineering/src/test/scala/dataengineering/MockerUtils.scala:191: object JavaConversions in package collection is deprecated (since 2.12.0): use JavaConverters
      case e: MultiException => e.getThrowables.exists(isBindCollision)
                                  ^
one warning found

> Task :processTestResources
> Task :testClasses

> Task :test
Discovery starting.
Discovery completed in 5 seconds, 491 milliseconds.
Run starting. Expected test count is: 9
19/05/23 01:37:00 INFO SparkContext: Running Spark version 2.4.3
19/05/23 01:37:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/05/23 01:37:01 INFO SparkContext: Submitted application: dataengineering_test
19/05/23 01:37:01 INFO SparkContext: Spark configuration:
datanucleus.rdbms.datastoreAdapterClassName=org.datanucleus.store.rdbms.adapter.DerbyAdapter
hive.exec.dynamic.partition=true
hive.exec.dynamic.partition.mode=nonstrict
hive.metastore.uris=
javax.jdo.option.ConnectionURL=jdbc:derby:;databaseName=/tmp/spark-e325226c-6db3-4a99-acae-5158f57ae82b/metastore;create=true
spark.app.id=dataengineering.LoadFraudTest25705
spark.app.name=dataengineering_test
spark.logConf=true
spark.master=local[2]
spark.sql.catalogImplementation=hive
spark.sql.codegen.fallback=false
spark.sql.parquet.compression.codec=snappy
spark.sql.shuffle.partitions=1
spark.sql.streaming.checkpointLocation=/tmp/spark-e325226c-6db3-4a99-acae-5158f57ae82b
spark.sql.warehouse.dir=/tmp/spark-e325226c-6db3-4a99-acae-5158f57ae82b/warehouse
spark.ui.enabled=false
19/05/23 01:37:01 INFO SecurityManager: Changing view acls to: root
19/05/23 01:37:01 INFO SecurityManager: Changing modify acls to: root
19/05/23 01:37:01 INFO SecurityManager: Changing view acls groups to: 
19/05/23 01:37:01 INFO SecurityManager: Changing modify acls groups to: 
19/05/23 01:37:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/05/23 01:37:02 INFO Utils: Successfully started service 'sparkDriver' on port 43787.
19/05/23 01:37:02 INFO SparkEnv: Registering MapOutputTracker
19/05/23 01:37:02 INFO SparkEnv: Registering BlockManagerMaster
19/05/23 01:37:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/05/23 01:37:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/05/23 01:37:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-938a187d-80d0-46e9-bf44-26b42673e322
19/05/23 01:37:02 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/05/23 01:37:02 INFO SparkEnv: Registering OutputCommitCoordinator
19/05/23 01:37:02 INFO Executor: Starting executor ID driver on host localhost
19/05/23 01:37:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36833.
19/05/23 01:37:02 INFO NettyBlockTransferService: Server created on dataengineering:36833
19/05/23 01:37:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/05/23 01:37:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, dataengineering, 36833, None)
19/05/23 01:37:02 INFO BlockManagerMasterEndpoint: Registering block manager dataengineering:36833 with 912.3 MB RAM, BlockManagerId(driver, dataengineering, 36833, None)
19/05/23 01:37:02 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, dataengineering, 36833, None)
19/05/23 01:37:02 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, dataengineering, 36833, None)
19/05/23 01:37:03 INFO log: Logging initialized @10889ms
19/05/23 01:37:04 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('/tmp/spark-e325226c-6db3-4a99-acae-5158f57ae82b/warehouse').
19/05/23 01:37:04 INFO SharedState: Warehouse path is '/tmp/spark-e325226c-6db3-4a99-acae-5158f57ae82b/warehouse'.
19/05/23 01:37:04 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/05/23 01:37:04 INFO Spark: ########## Reading compressed file inside /apps/dataengineering/build/resources/test/datasets/fraud.zip to a RDD of class String
19/05/23 01:37:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 333.8 KB, free 912.0 MB)
19/05/23 01:37:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 28.0 KB, free 911.9 MB)
19/05/23 01:37:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on dataengineering:36833 (size: 28.0 KB, free: 912.3 MB)
19/05/23 01:37:05 INFO SparkContext: Created broadcast 0 from binaryFiles at Spark.scala:24
19/05/23 01:37:05 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
19/05/23 01:37:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/05/23 01:37:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/05/23 01:37:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/05/23 01:37:05 INFO FileInputFormat: Total input files to process : 1
19/05/23 01:37:05 INFO FileInputFormat: Total input files to process : 1
19/05/23 01:37:05 INFO CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 14929
19/05/23 01:37:05 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
19/05/23 01:37:06 INFO DAGScheduler: Got job 0 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
19/05/23 01:37:06 INFO DAGScheduler: Final stage: ResultStage 0 (runJob at SparkHadoopWriter.scala:78)
19/05/23 01:37:06 INFO DAGScheduler: Parents of final stage: List()
19/05/23 01:37:06 INFO DAGScheduler: Missing parents: List()
19/05/23 01:37:06 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at saveAsTextFile at ZipFileLoader.scala:30), which has no missing parents
19/05/23 01:37:06 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 85.6 KB, free 911.9 MB)
19/05/23 01:37:06 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 31.0 KB, free 911.8 MB)
19/05/23 01:37:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on dataengineering:36833 (size: 31.0 KB, free: 912.2 MB)
19/05/23 01:37:06 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at saveAsTextFile at ZipFileLoader.scala:30) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/05/23 01:37:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7481 bytes)
19/05/23 01:37:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/05/23 01:37:06 INFO BinaryFileRDD: Input split: Paths:/apps/dataengineering/build/resources/test/datasets/fraud.zip:0+14929
19/05/23 01:37:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/05/23 01:37:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/05/23 01:37:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/05/23 01:37:07 INFO FileOutputCommitter: Saved output of task 'attempt_20190523013705_0002_m_000000_0' to file:/tmp/spark-e325226c-6db3-4a99-acae-5158f57ae82bfraud/_temporary/0/task_20190523013705_0002_m_000000
19/05/23 01:37:07 INFO SparkHadoopMapRedUtil: attempt_20190523013705_0002_m_000000_0: Committed
19/05/23 01:37:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1121 bytes result sent to driver
19/05/23 01:37:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 988 ms on localhost (executor driver) (1/1)
19/05/23 01:37:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/05/23 01:37:07 INFO DAGScheduler: ResultStage 0 (runJob at SparkHadoopWriter.scala:78) finished in 1.300 s
19/05/23 01:37:07 INFO DAGScheduler: Job 0 finished: runJob at SparkHadoopWriter.scala:78, took 1.447763 s
19/05/23 01:37:07 INFO SparkHadoopWriter: Job job_20190523013705_0002 committed.
19/05/23 01:37:07 WARN ZipFileLoader: ########## /tmp/spark-e325226c-6db3-4a99-acae-5158f57ae82bfraud file set to delete on JVM exit
19/05/23 01:37:07 INFO ZipFileLoader: ########## Applying provided schema
root
 |-- credit_card_number: long (nullable = true)
 |-- ipv4: string (nullable = true)
 |-- state: string (nullable = true)

LoadFraudTest:
19/05/23 01:37:09 INFO FileSourceStrategy: Pruning directories with: 
19/05/23 01:37:09 INFO FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, credit_card_number#0L,ipv4#1,state#2)
19/05/23 01:37:09 INFO FileSourceStrategy: Output Data Schema: struct<credit_card_number: bigint, ipv4: string, state: string ... 1 more fields>
19/05/23 01:37:09 INFO FileSourceScanExec: Pushed Filters: 
19/05/23 01:37:10 INFO CodeGenerator: Code generated in 373.8664 ms
19/05/23 01:37:10 INFO CodeGenerator: Code generated in 34.8237 ms
19/05/23 01:37:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.6 KB, free 911.5 MB)
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 9
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 15
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 18
19/05/23 01:37:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 28.7 KB, free 911.5 MB)
19/05/23 01:37:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on dataengineering:36833 (size: 28.7 KB, free: 912.2 MB)
19/05/23 01:37:10 INFO SparkContext: Created broadcast 2 from count at LoadFraudTest.scala:37
19/05/23 01:37:10 INFO BlockManagerInfo: Removed broadcast_0_piece0 on dataengineering:36833 in memory (size: 28.0 KB, free: 912.2 MB)
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 8
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 24
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 13
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 12
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 17
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 11
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 16
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 25
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 6
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 19
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 10
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 5
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 0
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 23
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 4
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 2
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 22
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 1
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 21
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 20
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 7
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 3
19/05/23 01:37:10 INFO BlockManagerInfo: Removed broadcast_1_piece0 on dataengineering:36833 in memory (size: 31.0 KB, free: 912.3 MB)
19/05/23 01:37:10 INFO ContextCleaner: Cleaned accumulator 14
19/05/23 01:37:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/05/23 01:37:10 INFO SparkContext: Starting job: count at LoadFraudTest.scala:37
19/05/23 01:37:10 INFO DAGScheduler: Registering RDD 5 (count at LoadFraudTest.scala:37)
19/05/23 01:37:10 INFO DAGScheduler: Got job 1 (count at LoadFraudTest.scala:37) with 1 output partitions
19/05/23 01:37:10 INFO DAGScheduler: Final stage: ResultStage 2 (count at LoadFraudTest.scala:37)
19/05/23 01:37:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/05/23 01:37:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/05/23 01:37:10 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at count at LoadFraudTest.scala:37), which has no missing parents
19/05/23 01:37:10 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.6 KB, free 911.9 MB)
19/05/23 01:37:10 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.4 KB, free 911.9 MB)
19/05/23 01:37:10 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on dataengineering:36833 (size: 7.4 KB, free: 912.3 MB)
19/05/23 01:37:10 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at count at LoadFraudTest.scala:37) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/05/23 01:37:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7816 bytes)
19/05/23 01:37:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/05/23 01:37:11 INFO FileScanRDD: Reading File path: file:///tmp/spark-e325226c-6db3-4a99-acae-5158f57ae82bfraud/part-00000, range: 0-31746, partition values: [empty row]
19/05/23 01:37:11 INFO CodeGenerator: Code generated in 42.2162 ms
19/05/23 01:37:11 WARN CSVDataSource: Number of column in CSV header is not equal to number of fields in the schema:
 Header length: 2, schema size: 3
CSV file: file:///tmp/spark-e325226c-6db3-4a99-acae-5158f57ae82bfraud/part-00000
19/05/23 01:37:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1706 bytes result sent to driver
19/05/23 01:37:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 600 ms on localhost (executor driver) (1/1)
19/05/23 01:37:11 INFO DAGScheduler: ShuffleMapStage 1 (count at LoadFraudTest.scala:37) finished in 0.681 s
19/05/23 01:37:11 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:11 INFO DAGScheduler: running: Set()
19/05/23 01:37:11 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/05/23 01:37:11 INFO DAGScheduler: failed: Set()
19/05/23 01:37:11 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[8] at count at LoadFraudTest.scala:37), which has no missing parents
19/05/23 01:37:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/05/23 01:37:11 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.5 KB, free 911.9 MB)
19/05/23 01:37:11 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 911.9 MB)
19/05/23 01:37:11 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on dataengineering:36833 (size: 4.4 KB, free: 912.3 MB)
19/05/23 01:37:11 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at count at LoadFraudTest.scala:37) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/05/23 01:37:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 7246 bytes)
19/05/23 01:37:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/05/23 01:37:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
19/05/23 01:37:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1792 bytes result sent to driver
19/05/23 01:37:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 198 ms on localhost (executor driver) (1/1)
19/05/23 01:37:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/05/23 01:37:11 INFO DAGScheduler: ResultStage 2 (count at LoadFraudTest.scala:37) finished in 0.211 s
19/05/23 01:37:11 INFO DAGScheduler: Job 1 finished: count at LoadFraudTest.scala:37, took 0.954135 s
- Load Fraud Zip file into DataFrame (8 seconds, 94 milliseconds)
19/05/23 01:37:11 INFO FileSourceStrategy: Pruning directories with: 
19/05/23 01:37:11 INFO FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, credit_card_number#0L,ipv4#1,state#2)
19/05/23 01:37:11 INFO FileSourceStrategy: Output Data Schema: struct<credit_card_number: bigint, ipv4: string, state: string ... 1 more fields>
19/05/23 01:37:11 INFO FileSourceScanExec: Pushed Filters: 
19/05/23 01:37:12 INFO CodeGenerator: Code generated in 16.0303 ms
19/05/23 01:37:12 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 338.6 KB, free 911.6 MB)
19/05/23 01:37:12 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 28.7 KB, free 911.5 MB)
19/05/23 01:37:12 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on dataengineering:36833 (size: 28.7 KB, free: 912.2 MB)
19/05/23 01:37:12 INFO SparkContext: Created broadcast 5 from jdbc at JDBC.scala:54
19/05/23 01:37:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/05/23 01:37:12 INFO SparkContext: Starting job: jdbc at JDBC.scala:54
19/05/23 01:37:12 INFO DAGScheduler: Registering RDD 12 (jdbc at JDBC.scala:54)
19/05/23 01:37:12 INFO DAGScheduler: Got job 2 (jdbc at JDBC.scala:54) with 2 output partitions
19/05/23 01:37:12 INFO DAGScheduler: Final stage: ResultStage 4 (jdbc at JDBC.scala:54)
19/05/23 01:37:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/05/23 01:37:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/05/23 01:37:12 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[12] at jdbc at JDBC.scala:54), which has no missing parents
19/05/23 01:37:12 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 14.4 KB, free 911.5 MB)
19/05/23 01:37:12 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KB, free 911.5 MB)
19/05/23 01:37:12 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on dataengineering:36833 (size: 7.2 KB, free: 912.2 MB)
19/05/23 01:37:12 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[12] at jdbc at JDBC.scala:54) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:12 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/05/23 01:37:12 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7816 bytes)
19/05/23 01:37:12 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/05/23 01:37:12 INFO FileScanRDD: Reading File path: file:///tmp/spark-e325226c-6db3-4a99-acae-5158f57ae82bfraud/part-00000, range: 0-31746, partition values: [empty row]
19/05/23 01:37:12 WARN CSVDataSource: Number of column in CSV header is not equal to number of fields in the schema:
 Header length: 2, schema size: 3
CSV file: file:///tmp/spark-e325226c-6db3-4a99-acae-5158f57ae82bfraud/part-00000
19/05/23 01:37:12 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1463 bytes result sent to driver
19/05/23 01:37:12 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 107 ms on localhost (executor driver) (1/1)
19/05/23 01:37:12 INFO DAGScheduler: ShuffleMapStage 3 (jdbc at JDBC.scala:54) finished in 0.129 s
19/05/23 01:37:12 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:12 INFO DAGScheduler: running: Set()
19/05/23 01:37:12 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/05/23 01:37:12 INFO DAGScheduler: failed: Set()
19/05/23 01:37:12 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[15] at jdbc at JDBC.scala:54), which has no missing parents
19/05/23 01:37:12 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/05/23 01:37:12 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 17.1 KB, free 911.5 MB)
19/05/23 01:37:12 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 9.0 KB, free 911.5 MB)
19/05/23 01:37:12 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on dataengineering:36833 (size: 9.0 KB, free: 912.2 MB)
19/05/23 01:37:12 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[15] at jdbc at JDBC.scala:54) (first 15 tasks are for partitions Vector(0, 1))
19/05/23 01:37:12 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
19/05/23 01:37:12 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 7246 bytes)
19/05/23 01:37:12 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5, localhost, executor driver, partition 1, ANY, 7246 bytes)
19/05/23 01:37:12 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/05/23 01:37:12 INFO Executor: Running task 1.0 in stage 4.0 (TID 5)
19/05/23 01:37:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/05/23 01:37:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
19/05/23 01:37:12 INFO CodeGenerator: Code generated in 25.2489 ms
19/05/23 01:37:12 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1731 bytes result sent to driver
19/05/23 01:37:12 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 589 ms on localhost (executor driver) (1/2)
- Write Fraud DataFrame in MySQL table test.fraud (1 second, 139 milliseconds)
19/05/23 01:37:12 INFO Executor: Finished task 1.0 in stage 4.0 (TID 5). 1731 bytes result sent to driver
19/05/23 01:37:12 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 619 ms on localhost (executor driver) (2/2)
19/05/23 01:37:12 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/05/23 01:37:12 INFO DAGScheduler: ResultStage 4 (jdbc at JDBC.scala:54) finished in 0.678 s
19/05/23 01:37:12 INFO DAGScheduler: Job 2 finished: jdbc at JDBC.scala:54, took 0.817169 s
19/05/23 01:37:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/05/23 01:37:12 INFO MemoryStore: MemoryStore cleared
19/05/23 01:37:12 INFO BlockManager: BlockManager stopped
19/05/23 01:37:13 INFO BlockManagerMaster: BlockManagerMaster stopped
19/05/23 01:37:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/05/23 01:37:13 INFO SparkContext: Successfully stopped SparkContext
19/05/23 01:37:13 INFO SparkContext: Running Spark version 2.4.3
19/05/23 01:37:13 INFO SparkContext: Submitted application: dataengineering_test
19/05/23 01:37:13 INFO SparkContext: Spark configuration:
datanucleus.rdbms.datastoreAdapterClassName=org.datanucleus.store.rdbms.adapter.DerbyAdapter
hive.exec.dynamic.partition=true
hive.exec.dynamic.partition.mode=nonstrict
hive.metastore.uris=
javax.jdo.option.ConnectionURL=jdbc:derby:;databaseName=/tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110c/metastore;create=true
spark.app.id=dataengineering.LoadTransactionTest28515
spark.app.name=dataengineering_test
spark.logConf=true
spark.master=local[2]
spark.sql.catalogImplementation=hive
spark.sql.codegen.fallback=false
spark.sql.parquet.compression.codec=snappy
spark.sql.shuffle.partitions=1
spark.sql.streaming.checkpointLocation=/tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110c
spark.sql.warehouse.dir=/tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110c/warehouse
spark.ui.enabled=false
19/05/23 01:37:13 INFO SecurityManager: Changing view acls to: root
19/05/23 01:37:13 INFO SecurityManager: Changing modify acls to: root
19/05/23 01:37:13 INFO SecurityManager: Changing view acls groups to: 
19/05/23 01:37:13 INFO SecurityManager: Changing modify acls groups to: 
19/05/23 01:37:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/05/23 01:37:13 INFO Utils: Successfully started service 'sparkDriver' on port 39685.
19/05/23 01:37:13 INFO SparkEnv: Registering MapOutputTracker
19/05/23 01:37:13 INFO SparkEnv: Registering BlockManagerMaster
19/05/23 01:37:13 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/05/23 01:37:13 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/05/23 01:37:13 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d2fc51c5-26c3-4d08-b799-92b378e2761c
19/05/23 01:37:13 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/05/23 01:37:13 INFO SparkEnv: Registering OutputCommitCoordinator
LoadTransactionTest:
19/05/23 01:37:13 INFO Executor: Starting executor ID driver on host localhost
19/05/23 01:37:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33505.
19/05/23 01:37:13 INFO NettyBlockTransferService: Server created on dataengineering:33505
19/05/23 01:37:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/05/23 01:37:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, dataengineering, 33505, None)
19/05/23 01:37:13 INFO BlockManagerMasterEndpoint: Registering block manager dataengineering:33505 with 912.3 MB RAM, BlockManagerId(driver, dataengineering, 33505, None)
19/05/23 01:37:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, dataengineering, 33505, None)
19/05/23 01:37:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, dataengineering, 33505, None)
19/05/23 01:37:13 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('/tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110c/warehouse').
19/05/23 01:37:13 INFO SharedState: Warehouse path is '/tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110c/warehouse'.
19/05/23 01:37:13 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/05/23 01:37:13 INFO Spark: ########## Reading compressed file inside /apps/dataengineering/build/resources/test/datasets/transaction-001.zip to a RDD of class String
19/05/23 01:37:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 333.9 KB, free 912.0 MB)
19/05/23 01:37:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 28.1 KB, free 911.9 MB)
19/05/23 01:37:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on dataengineering:33505 (size: 28.1 KB, free: 912.3 MB)
19/05/23 01:37:13 INFO SparkContext: Created broadcast 0 from binaryFiles at Spark.scala:24
19/05/23 01:37:13 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/05/23 01:37:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/05/23 01:37:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/05/23 01:37:13 INFO FileInputFormat: Total input files to process : 1
19/05/23 01:37:13 INFO FileInputFormat: Total input files to process : 1
19/05/23 01:37:13 INFO CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 3630927
19/05/23 01:37:13 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
19/05/23 01:37:13 INFO DAGScheduler: Got job 0 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
19/05/23 01:37:13 INFO DAGScheduler: Final stage: ResultStage 0 (runJob at SparkHadoopWriter.scala:78)
19/05/23 01:37:13 INFO DAGScheduler: Parents of final stage: List()
19/05/23 01:37:13 INFO DAGScheduler: Missing parents: List()
19/05/23 01:37:13 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at saveAsTextFile at ZipFileLoader.scala:30), which has no missing parents
19/05/23 01:37:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 85.6 KB, free 911.9 MB)
19/05/23 01:37:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 31.0 KB, free 911.8 MB)
19/05/23 01:37:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on dataengineering:33505 (size: 31.0 KB, free: 912.2 MB)
19/05/23 01:37:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at saveAsTextFile at ZipFileLoader.scala:30) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/05/23 01:37:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7491 bytes)
19/05/23 01:37:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/05/23 01:37:13 INFO BinaryFileRDD: Input split: Paths:/apps/dataengineering/build/resources/test/datasets/transaction-001.zip:0+3630927
19/05/23 01:37:13 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/05/23 01:37:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/05/23 01:37:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/05/23 01:37:13 INFO FileOutputCommitter: Saved output of task 'attempt_20190523013713_0002_m_000000_0' to file:/tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-001/_temporary/0/task_20190523013713_0002_m_000000
19/05/23 01:37:13 INFO SparkHadoopMapRedUtil: attempt_20190523013713_0002_m_000000_0: Committed
19/05/23 01:37:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1121 bytes result sent to driver
19/05/23 01:37:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 597 ms on localhost (executor driver) (1/1)
19/05/23 01:37:13 INFO DAGScheduler: ResultStage 0 (runJob at SparkHadoopWriter.scala:78) finished in 0.630 s
19/05/23 01:37:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/05/23 01:37:13 INFO DAGScheduler: Job 0 finished: runJob at SparkHadoopWriter.scala:78, took 0.635743 s
19/05/23 01:37:14 INFO SparkHadoopWriter: Job job_20190523013713_0002 committed.
19/05/23 01:37:14 WARN ZipFileLoader: ########## /tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-001 file set to delete on JVM exit
19/05/23 01:37:14 INFO ZipFileLoader: ########## Applying provided schema
root
 |-- credit_card_number: long (nullable = true)
 |-- ipv4: string (nullable = true)
 |-- state: string (nullable = true)

19/05/23 01:37:14 INFO FileSourceStrategy: Pruning directories with: 
19/05/23 01:37:14 INFO FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, credit_card_number#30L,ipv4#31,state#32)
19/05/23 01:37:14 INFO FileSourceStrategy: Output Data Schema: struct<credit_card_number: bigint, ipv4: string, state: string ... 1 more fields>
19/05/23 01:37:14 INFO FileSourceScanExec: Pushed Filters: 
19/05/23 01:37:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.5 KB, free 911.5 MB)
19/05/23 01:37:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 28.6 KB, free 911.5 MB)
19/05/23 01:37:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on dataengineering:33505 (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:14 INFO SparkContext: Created broadcast 2 from count at LoadTransactionTest.scala:31
19/05/23 01:37:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6305133 bytes, open cost is considered as scanning 4194304 bytes.
19/05/23 01:37:14 INFO SparkContext: Starting job: count at LoadTransactionTest.scala:31
19/05/23 01:37:14 INFO DAGScheduler: Registering RDD 5 (count at LoadTransactionTest.scala:31)
19/05/23 01:37:14 INFO DAGScheduler: Got job 1 (count at LoadTransactionTest.scala:31) with 1 output partitions
19/05/23 01:37:14 INFO DAGScheduler: Final stage: ResultStage 2 (count at LoadTransactionTest.scala:31)
19/05/23 01:37:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/05/23 01:37:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/05/23 01:37:14 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at count at LoadTransactionTest.scala:31), which has no missing parents
19/05/23 01:37:14 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.6 KB, free 911.5 MB)
19/05/23 01:37:14 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.4 KB, free 911.5 MB)
19/05/23 01:37:14 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on dataengineering:33505 (size: 7.4 KB, free: 912.2 MB)
19/05/23 01:37:14 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at count at LoadTransactionTest.scala:31) (first 15 tasks are for partitions Vector(0, 1))
19/05/23 01:37:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
19/05/23 01:37:14 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7826 bytes)
19/05/23 01:37:14 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 7826 bytes)
19/05/23 01:37:14 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/05/23 01:37:14 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
19/05/23 01:37:14 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-001/part-00000, range: 0-6305133, partition values: [empty row]
19/05/23 01:37:14 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-001/part-00000, range: 6305133-8415963, partition values: [empty row]
19/05/23 01:37:14 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1620 bytes result sent to driver
19/05/23 01:37:14 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 530 ms on localhost (executor driver) (1/2)
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 174
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 156
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 165
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 175
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 154
19/05/23 01:37:14 INFO BlockManagerInfo: Removed broadcast_0_piece0 on dataengineering:33505 in memory (size: 28.1 KB, free: 912.2 MB)
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 173
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 169
19/05/23 01:37:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on dataengineering:33505 in memory (size: 31.0 KB, free: 912.3 MB)
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 163
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 167
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 178
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 159
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 170
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 160
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 157
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 153
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 162
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 158
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 164
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 161
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 155
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 172
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 166
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 177
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 171
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 176
19/05/23 01:37:14 INFO ContextCleaner: Cleaned accumulator 168
19/05/23 01:37:14 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1663 bytes result sent to driver
19/05/23 01:37:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 735 ms on localhost (executor driver) (2/2)
19/05/23 01:37:14 INFO DAGScheduler: ShuffleMapStage 1 (count at LoadTransactionTest.scala:31) finished in 0.753 s
19/05/23 01:37:14 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:14 INFO DAGScheduler: running: Set()
19/05/23 01:37:14 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/05/23 01:37:14 INFO DAGScheduler: failed: Set()
19/05/23 01:37:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[8] at count at LoadTransactionTest.scala:31), which has no missing parents
19/05/23 01:37:14 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.5 KB, free 911.9 MB)
19/05/23 01:37:14 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 911.9 MB)
19/05/23 01:37:14 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on dataengineering:33505 (size: 4.4 KB, free: 912.3 MB)
19/05/23 01:37:14 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at count at LoadTransactionTest.scala:31) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/05/23 01:37:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/05/23 01:37:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, ANY, 7246 bytes)
19/05/23 01:37:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 3)
19/05/23 01:37:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
19/05/23 01:37:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/05/23 01:37:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 3). 1749 bytes result sent to driver
19/05/23 01:37:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 18 ms on localhost (executor driver) (1/1)
19/05/23 01:37:14 INFO DAGScheduler: ResultStage 2 (count at LoadTransactionTest.scala:31) finished in 0.032 s
19/05/23 01:37:14 INFO DAGScheduler: Job 1 finished: count at LoadTransactionTest.scala:31, took 0.791192 s
19/05/23 01:37:14 INFO Spark: ########## Reading compressed file inside /apps/dataengineering/build/resources/test/datasets/transaction-002.zip to a RDD of class String
19/05/23 01:37:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/05/23 01:37:14 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 333.9 KB, free 911.6 MB)
19/05/23 01:37:14 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 28.1 KB, free 911.6 MB)
19/05/23 01:37:14 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on dataengineering:33505 (size: 28.1 KB, free: 912.2 MB)
19/05/23 01:37:14 INFO SparkContext: Created broadcast 5 from binaryFiles at Spark.scala:24
19/05/23 01:37:14 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/05/23 01:37:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/05/23 01:37:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/05/23 01:37:14 INFO FileInputFormat: Total input files to process : 1
19/05/23 01:37:14 INFO FileInputFormat: Total input files to process : 1
19/05/23 01:37:14 INFO CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 3630537
19/05/23 01:37:14 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
19/05/23 01:37:14 INFO DAGScheduler: Got job 2 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
19/05/23 01:37:14 INFO DAGScheduler: Final stage: ResultStage 3 (runJob at SparkHadoopWriter.scala:78)
19/05/23 01:37:14 INFO DAGScheduler: Parents of final stage: List()
19/05/23 01:37:14 INFO DAGScheduler: Missing parents: List()
19/05/23 01:37:14 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at saveAsTextFile at ZipFileLoader.scala:30), which has no missing parents
19/05/23 01:37:14 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 85.6 KB, free 911.5 MB)
19/05/23 01:37:14 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 31.0 KB, free 911.4 MB)
19/05/23 01:37:14 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on dataengineering:33505 (size: 31.0 KB, free: 912.2 MB)
19/05/23 01:37:14 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at saveAsTextFile at ZipFileLoader.scala:30) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:14 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/05/23 01:37:14 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7491 bytes)
19/05/23 01:37:14 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
19/05/23 01:37:14 INFO BinaryFileRDD: Input split: Paths:/apps/dataengineering/build/resources/test/datasets/transaction-002.zip:0+3630537
19/05/23 01:37:14 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/05/23 01:37:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/05/23 01:37:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/05/23 01:37:15 INFO FileOutputCommitter: Saved output of task 'attempt_20190523013714_0011_m_000000_0' to file:/tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-002/_temporary/0/task_20190523013714_0011_m_000000
19/05/23 01:37:15 INFO SparkHadoopMapRedUtil: attempt_20190523013714_0011_m_000000_0: Committed
19/05/23 01:37:15 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 1078 bytes result sent to driver
19/05/23 01:37:15 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 365 ms on localhost (executor driver) (1/1)
19/05/23 01:37:15 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/05/23 01:37:15 INFO DAGScheduler: ResultStage 3 (runJob at SparkHadoopWriter.scala:78) finished in 0.381 s
19/05/23 01:37:15 INFO DAGScheduler: Job 2 finished: runJob at SparkHadoopWriter.scala:78, took 0.384106 s
19/05/23 01:37:15 INFO SparkHadoopWriter: Job job_20190523013714_0011 committed.
19/05/23 01:37:15 WARN ZipFileLoader: ########## /tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-002 file set to delete on JVM exit
19/05/23 01:37:15 INFO ZipFileLoader: ########## Applying provided schema
root
 |-- credit_card_number: long (nullable = true)
 |-- ipv4: string (nullable = true)
 |-- state: string (nullable = true)

19/05/23 01:37:15 INFO FileSourceStrategy: Pruning directories with: 
19/05/23 01:37:15 INFO FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, credit_card_number#50L,ipv4#51,state#52)
19/05/23 01:37:15 INFO FileSourceStrategy: Output Data Schema: struct<credit_card_number: bigint, ipv4: string, state: string ... 1 more fields>
19/05/23 01:37:15 INFO FileSourceScanExec: Pushed Filters: 
19/05/23 01:37:15 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 338.5 KB, free 911.1 MB)
19/05/23 01:37:15 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 28.6 KB, free 911.1 MB)
19/05/23 01:37:15 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on dataengineering:33505 (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:15 INFO SparkContext: Created broadcast 7 from count at LoadTransactionTest.scala:35
19/05/23 01:37:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6305147 bytes, open cost is considered as scanning 4194304 bytes.
19/05/23 01:37:15 INFO SparkContext: Starting job: count at LoadTransactionTest.scala:35
19/05/23 01:37:15 INFO DAGScheduler: Registering RDD 14 (count at LoadTransactionTest.scala:35)
19/05/23 01:37:15 INFO DAGScheduler: Got job 3 (count at LoadTransactionTest.scala:35) with 1 output partitions
19/05/23 01:37:15 INFO DAGScheduler: Final stage: ResultStage 5 (count at LoadTransactionTest.scala:35)
19/05/23 01:37:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
19/05/23 01:37:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
19/05/23 01:37:15 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at count at LoadTransactionTest.scala:35), which has no missing parents
19/05/23 01:37:15 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.6 KB, free 911.1 MB)
19/05/23 01:37:15 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.4 KB, free 911.1 MB)
19/05/23 01:37:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on dataengineering:33505 (size: 7.4 KB, free: 912.2 MB)
19/05/23 01:37:15 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at count at LoadTransactionTest.scala:35) (first 15 tasks are for partitions Vector(0, 1))
19/05/23 01:37:15 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
19/05/23 01:37:15 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 7826 bytes)
19/05/23 01:37:15 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 7826 bytes)
19/05/23 01:37:15 INFO Executor: Running task 0.0 in stage 4.0 (TID 5)
19/05/23 01:37:15 INFO Executor: Running task 1.0 in stage 4.0 (TID 6)
19/05/23 01:37:15 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-002/part-00000, range: 6305147-8415991, partition values: [empty row]
19/05/23 01:37:15 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-002/part-00000, range: 0-6305147, partition values: [empty row]
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 207
19/05/23 01:37:15 INFO BlockManagerInfo: Removed broadcast_4_piece0 on dataengineering:33505 in memory (size: 4.4 KB, free: 912.2 MB)
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 184
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 234
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 185
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 196
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 243
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 228
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 227
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 218
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 215
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 223
19/05/23 01:37:15 INFO BlockManagerInfo: Removed broadcast_5_piece0 on dataengineering:33505 in memory (size: 28.1 KB, free: 912.2 MB)
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 212
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 261
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 213
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 201
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 204
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 217
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 200
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 235
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 239
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 180
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 237
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 260
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 210
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 259
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 205
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 253
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 183
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 238
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 230
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 224
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 264
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 197
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 233
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 221
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 236
19/05/23 01:37:15 INFO ContextCleaner: Cleaned shuffle 0
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 242
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 188
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 245
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 195
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 198
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 191
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 240
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 182
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 232
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 254
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 208
19/05/23 01:37:15 INFO BlockManagerInfo: Removed broadcast_2_piece0 on dataengineering:33505 in memory (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 225
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 270
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 193
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 248
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 220
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 246
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 265
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 249
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 206
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 189
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 209
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 192
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 203
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 231
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 214
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 187
19/05/23 01:37:15 INFO BlockManagerInfo: Removed broadcast_6_piece0 on dataengineering:33505 in memory (size: 31.0 KB, free: 912.3 MB)
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 226
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 222
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 244
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 251
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 268
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 229
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 266
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 202
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 255
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 179
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 256
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 250
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 181
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 262
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 219
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 271
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 216
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 257
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 267
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 194
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 241
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 258
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 272
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 269
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 211
19/05/23 01:37:15 INFO BlockManagerInfo: Removed broadcast_3_piece0 on dataengineering:33505 in memory (size: 7.4 KB, free: 912.3 MB)
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 199
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 190
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 247
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 263
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 186
19/05/23 01:37:15 INFO ContextCleaner: Cleaned accumulator 252
19/05/23 01:37:15 INFO Executor: Finished task 1.0 in stage 4.0 (TID 6). 1663 bytes result sent to driver
19/05/23 01:37:15 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 6) in 292 ms on localhost (executor driver) (1/2)
19/05/23 01:37:15 INFO Executor: Finished task 0.0 in stage 4.0 (TID 5). 1706 bytes result sent to driver
19/05/23 01:37:15 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 5) in 450 ms on localhost (executor driver) (2/2)
19/05/23 01:37:15 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/05/23 01:37:15 INFO DAGScheduler: ShuffleMapStage 4 (count at LoadTransactionTest.scala:35) finished in 0.462 s
19/05/23 01:37:15 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:15 INFO DAGScheduler: running: Set()
19/05/23 01:37:15 INFO DAGScheduler: waiting: Set(ResultStage 5)
19/05/23 01:37:15 INFO DAGScheduler: failed: Set()
19/05/23 01:37:15 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[17] at count at LoadTransactionTest.scala:35), which has no missing parents
19/05/23 01:37:15 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 8.5 KB, free 911.9 MB)
19/05/23 01:37:15 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.4 KB, free 911.9 MB)
19/05/23 01:37:15 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on dataengineering:33505 (size: 4.4 KB, free: 912.3 MB)
19/05/23 01:37:15 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at count at LoadTransactionTest.scala:35) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:15 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/05/23 01:37:15 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 7, localhost, executor driver, partition 0, ANY, 7246 bytes)
19/05/23 01:37:15 INFO Executor: Running task 0.0 in stage 5.0 (TID 7)
19/05/23 01:37:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
19/05/23 01:37:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/05/23 01:37:15 INFO Executor: Finished task 0.0 in stage 5.0 (TID 7). 1749 bytes result sent to driver
19/05/23 01:37:15 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 7) in 16 ms on localhost (executor driver) (1/1)
19/05/23 01:37:15 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/05/23 01:37:15 INFO DAGScheduler: ResultStage 5 (count at LoadTransactionTest.scala:35) finished in 0.022 s
19/05/23 01:37:15 INFO DAGScheduler: Job 3 finished: count at LoadTransactionTest.scala:35, took 0.490151 s
- Load transaction zip files to DataFrame (2 seconds, 725 milliseconds)
19/05/23 01:37:16 INFO FileSourceStrategy: Pruning directories with: 
19/05/23 01:37:16 INFO FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, credit_card_number#30L,ipv4#31,state#32)
19/05/23 01:37:16 INFO FileSourceStrategy: Output Data Schema: struct<credit_card_number: bigint, ipv4: string, state: string ... 1 more fields>
19/05/23 01:37:16 INFO FileSourceScanExec: Pushed Filters: 
19/05/23 01:37:16 INFO FileSourceStrategy: Pruning directories with: 
19/05/23 01:37:16 INFO FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, credit_card_number#50L,ipv4#51,state#52)
19/05/23 01:37:16 INFO FileSourceStrategy: Output Data Schema: struct<credit_card_number: bigint, ipv4: string, state: string ... 1 more fields>
19/05/23 01:37:16 INFO FileSourceScanExec: Pushed Filters: 
19/05/23 01:37:16 INFO CodeGenerator: Code generated in 31.637 ms
19/05/23 01:37:16 INFO CodeGenerator: Code generated in 20.7071 ms
19/05/23 01:37:16 INFO CodeGenerator: Code generated in 28.4435 ms
19/05/23 01:37:16 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 338.5 KB, free 911.6 MB)
19/05/23 01:37:16 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 28.6 KB, free 911.5 MB)
19/05/23 01:37:16 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on dataengineering:33505 (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:16 INFO SparkContext: Created broadcast 10 from count at LoadTransactionTest.scala:41
19/05/23 01:37:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6305133 bytes, open cost is considered as scanning 4194304 bytes.
19/05/23 01:37:16 INFO CodeGenerator: Code generated in 19.0191 ms
19/05/23 01:37:16 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 338.5 KB, free 911.2 MB)
19/05/23 01:37:16 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 28.6 KB, free 911.2 MB)
19/05/23 01:37:16 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on dataengineering:33505 (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:16 INFO SparkContext: Created broadcast 11 from count at LoadTransactionTest.scala:41
19/05/23 01:37:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6305147 bytes, open cost is considered as scanning 4194304 bytes.
19/05/23 01:37:16 INFO SparkContext: Starting job: count at LoadTransactionTest.scala:41
19/05/23 01:37:16 INFO DAGScheduler: Registering RDD 24 (count at LoadTransactionTest.scala:41)
19/05/23 01:37:16 INFO DAGScheduler: Got job 4 (count at LoadTransactionTest.scala:41) with 1 output partitions
19/05/23 01:37:16 INFO DAGScheduler: Final stage: ResultStage 7 (count at LoadTransactionTest.scala:41)
19/05/23 01:37:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
19/05/23 01:37:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
19/05/23 01:37:16 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[24] at count at LoadTransactionTest.scala:41), which has no missing parents
19/05/23 01:37:16 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 19.8 KB, free 911.2 MB)
19/05/23 01:37:16 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.3 KB, free 911.2 MB)
19/05/23 01:37:16 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on dataengineering:33505 (size: 8.3 KB, free: 912.2 MB)
19/05/23 01:37:16 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:16 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[24] at count at LoadTransactionTest.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/05/23 01:37:16 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
19/05/23 01:37:16 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 7935 bytes)
19/05/23 01:37:16 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 7935 bytes)
19/05/23 01:37:16 INFO Executor: Running task 0.0 in stage 6.0 (TID 8)
19/05/23 01:37:16 INFO Executor: Running task 1.0 in stage 6.0 (TID 9)
19/05/23 01:37:16 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-001/part-00000, range: 0-6305133, partition values: [empty row]
19/05/23 01:37:16 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-001/part-00000, range: 6305133-8415963, partition values: [empty row]
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 283
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 321
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 327
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 274
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 322
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 329
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 314
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 324
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 315
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 308
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 326
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 311
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 302
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 295
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 310
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 333
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 312
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 277
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 288
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 338
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 334
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 309
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 341
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 319
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 330
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 278
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 287
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 290
19/05/23 01:37:16 INFO BlockManagerInfo: Removed broadcast_7_piece0 on dataengineering:33505 in memory (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 293
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 304
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 279
19/05/23 01:37:16 INFO ContextCleaner: Cleaned shuffle 1
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 332
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 281
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 301
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 306
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 316
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 318
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 323
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 340
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 286
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 337
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 285
19/05/23 01:37:16 INFO BlockManagerInfo: Removed broadcast_9_piece0 on dataengineering:33505 in memory (size: 4.4 KB, free: 912.2 MB)
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 328
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 291
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 300
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 335
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 307
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 296
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 289
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 297
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 276
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 313
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 331
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 325
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 320
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 294
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 298
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 317
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 336
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 280
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 275
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 299
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 282
19/05/23 01:37:16 INFO BlockManagerInfo: Removed broadcast_8_piece0 on dataengineering:33505 in memory (size: 7.4 KB, free: 912.2 MB)
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 284
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 305
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 303
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 339
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 273
19/05/23 01:37:16 INFO ContextCleaner: Cleaned accumulator 292
19/05/23 01:37:16 INFO Executor: Finished task 1.0 in stage 6.0 (TID 9). 2010 bytes result sent to driver
19/05/23 01:37:16 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 10, localhost, executor driver, partition 2, PROCESS_LOCAL, 7935 bytes)
19/05/23 01:37:16 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 9) in 458 ms on localhost (executor driver) (1/4)
19/05/23 01:37:16 INFO Executor: Running task 2.0 in stage 6.0 (TID 10)
19/05/23 01:37:16 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-002/part-00000, range: 0-6305147, partition values: [empty row]
19/05/23 01:37:16 INFO Executor: Finished task 0.0 in stage 6.0 (TID 8). 1967 bytes result sent to driver
19/05/23 01:37:16 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 11, localhost, executor driver, partition 3, PROCESS_LOCAL, 7935 bytes)
19/05/23 01:37:16 INFO Executor: Running task 3.0 in stage 6.0 (TID 11)
19/05/23 01:37:16 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 8) in 603 ms on localhost (executor driver) (2/4)
19/05/23 01:37:16 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-002/part-00000, range: 6305147-8415991, partition values: [empty row]
19/05/23 01:37:17 INFO Executor: Finished task 3.0 in stage 6.0 (TID 11). 1924 bytes result sent to driver
19/05/23 01:37:17 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 11) in 300 ms on localhost (executor driver) (3/4)
19/05/23 01:37:17 INFO Executor: Finished task 2.0 in stage 6.0 (TID 10). 1967 bytes result sent to driver
19/05/23 01:37:17 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 10) in 652 ms on localhost (executor driver) (4/4)
19/05/23 01:37:17 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/05/23 01:37:17 INFO DAGScheduler: ShuffleMapStage 6 (count at LoadTransactionTest.scala:41) finished in 1.120 s
19/05/23 01:37:17 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:17 INFO DAGScheduler: running: Set()
19/05/23 01:37:17 INFO DAGScheduler: waiting: Set(ResultStage 7)
19/05/23 01:37:17 INFO DAGScheduler: failed: Set()
19/05/23 01:37:17 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[27] at count at LoadTransactionTest.scala:41), which has no missing parents
19/05/23 01:37:17 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.5 KB, free 911.5 MB)
19/05/23 01:37:17 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.4 KB, free 911.5 MB)
19/05/23 01:37:17 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on dataengineering:33505 (size: 4.4 KB, free: 912.2 MB)
19/05/23 01:37:17 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[27] at count at LoadTransactionTest.scala:41) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:17 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
- Check count of transaction DataFrame (1 second, 493 milliseconds)
19/05/23 01:37:17 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 12, localhost, executor driver, partition 0, ANY, 7246 bytes)
19/05/23 01:37:17 INFO Executor: Running task 0.0 in stage 7.0 (TID 12)
19/05/23 01:37:17 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
19/05/23 01:37:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/05/23 01:37:17 INFO Executor: Finished task 0.0 in stage 7.0 (TID 12). 1749 bytes result sent to driver
19/05/23 01:37:17 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 12) in 11 ms on localhost (executor driver) (1/1)
19/05/23 01:37:17 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/05/23 01:37:17 INFO DAGScheduler: ResultStage 7 (count at LoadTransactionTest.scala:41) finished in 0.018 s
19/05/23 01:37:17 INFO DAGScheduler: Job 4 finished: count at LoadTransactionTest.scala:41, took 1.146542 s
19/05/23 01:37:17 INFO FileSourceStrategy: Pruning directories with: 
19/05/23 01:37:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(credit_card_number#30L),AtLeastNNulls(n, credit_card_number#30L,ipv4#31,state#32),NOT cast(credit_card_number#30L as string) RLIKE ^(34|37|2131|1800|51|52|54|55|222%|4|5018|5020|5038|56##|300|301|304|305|36|38|6011|65|35)(.*)+$
19/05/23 01:37:17 INFO FileSourceStrategy: Output Data Schema: struct<credit_card_number: bigint, ipv4: string, state: string ... 1 more fields>
19/05/23 01:37:17 INFO FileSourceScanExec: Pushed Filters: IsNotNull(credit_card_number)
19/05/23 01:37:17 INFO FileSourceStrategy: Pruning directories with: 
19/05/23 01:37:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(credit_card_number#50L),AtLeastNNulls(n, credit_card_number#50L,ipv4#51,state#52),NOT cast(credit_card_number#50L as string) RLIKE ^(34|37|2131|1800|51|52|54|55|222%|4|5018|5020|5038|56##|300|301|304|305|36|38|6011|65|35)(.*)+$
19/05/23 01:37:17 INFO FileSourceStrategy: Output Data Schema: struct<credit_card_number: bigint, ipv4: string, state: string ... 1 more fields>
19/05/23 01:37:17 INFO FileSourceScanExec: Pushed Filters: IsNotNull(credit_card_number)
19/05/23 01:37:17 INFO CodeGenerator: Code generated in 33.3737 ms
19/05/23 01:37:17 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 338.5 KB, free 911.2 MB)
19/05/23 01:37:17 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 28.6 KB, free 911.2 MB)
19/05/23 01:37:17 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on dataengineering:33505 (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:17 INFO SparkContext: Created broadcast 14 from count at LoadTransactionTest.scala:46
19/05/23 01:37:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6305133 bytes, open cost is considered as scanning 4194304 bytes.
19/05/23 01:37:17 INFO CodeGenerator: Code generated in 17.8117 ms
19/05/23 01:37:17 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 338.5 KB, free 910.9 MB)
19/05/23 01:37:17 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 28.6 KB, free 910.8 MB)
19/05/23 01:37:17 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on dataengineering:33505 (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:17 INFO SparkContext: Created broadcast 15 from count at LoadTransactionTest.scala:46
19/05/23 01:37:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6305147 bytes, open cost is considered as scanning 4194304 bytes.
19/05/23 01:37:17 INFO SparkContext: Starting job: count at LoadTransactionTest.scala:46
19/05/23 01:37:17 INFO DAGScheduler: Registering RDD 34 (count at LoadTransactionTest.scala:46)
19/05/23 01:37:17 INFO DAGScheduler: Got job 5 (count at LoadTransactionTest.scala:46) with 1 output partitions
19/05/23 01:37:17 INFO DAGScheduler: Final stage: ResultStage 9 (count at LoadTransactionTest.scala:46)
19/05/23 01:37:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
19/05/23 01:37:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
19/05/23 01:37:17 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[34] at count at LoadTransactionTest.scala:46), which has no missing parents
19/05/23 01:37:17 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 21.3 KB, free 910.8 MB)
19/05/23 01:37:17 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.7 KB, free 910.8 MB)
19/05/23 01:37:17 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on dataengineering:33505 (size: 8.7 KB, free: 912.2 MB)
19/05/23 01:37:17 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:17 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[34] at count at LoadTransactionTest.scala:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/05/23 01:37:17 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
19/05/23 01:37:17 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 7935 bytes)
19/05/23 01:37:17 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 14, localhost, executor driver, partition 1, PROCESS_LOCAL, 7935 bytes)
19/05/23 01:37:17 INFO Executor: Running task 1.0 in stage 8.0 (TID 14)
19/05/23 01:37:17 INFO Executor: Running task 0.0 in stage 8.0 (TID 13)
19/05/23 01:37:17 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-001/part-00000, range: 6305133-8415963, partition values: [empty row]
19/05/23 01:37:17 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-001/part-00000, range: 0-6305133, partition values: [empty row]
19/05/23 01:37:18 INFO Executor: Finished task 1.0 in stage 8.0 (TID 14). 1924 bytes result sent to driver
19/05/23 01:37:18 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 15, localhost, executor driver, partition 2, PROCESS_LOCAL, 7935 bytes)
19/05/23 01:37:18 INFO Executor: Running task 2.0 in stage 8.0 (TID 15)
19/05/23 01:37:18 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 14) in 321 ms on localhost (executor driver) (1/4)
19/05/23 01:37:18 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-002/part-00000, range: 0-6305147, partition values: [empty row]
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 416
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 371
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 354
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 383
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 377
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 404
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 379
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 343
19/05/23 01:37:18 INFO BlockManagerInfo: Removed broadcast_10_piece0 on dataengineering:33505 in memory (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 346
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 355
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 345
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 399
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 389
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 392
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 384
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 408
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 407
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 413
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 374
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 403
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 394
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 385
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 352
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 412
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 406
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 350
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 378
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 368
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 360
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 387
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 401
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 363
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 348
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 365
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 366
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 359
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 344
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 398
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 402
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 381
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 347
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 375
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 372
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 373
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 390
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 356
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 388
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 409
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 361
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 397
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 382
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 362
19/05/23 01:37:18 INFO BlockManagerInfo: Removed broadcast_12_piece0 on dataengineering:33505 in memory (size: 8.3 KB, free: 912.2 MB)
19/05/23 01:37:18 INFO BlockManagerInfo: Removed broadcast_11_piece0 on dataengineering:33505 in memory (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 358
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 369
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 349
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 400
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 342
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 370
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 364
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 353
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 396
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 391
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 367
19/05/23 01:37:18 INFO ContextCleaner: Cleaned accumulator 405
19/05/23 01:37:18 INFO BlockManagerInfo: Removed broadcast_13_piece0 on dataengineering:33505 in memory (size: 4.4 KB, free: 912.2 MB)
19/05/23 01:37:19 INFO ContextCleaner: Cleaned accumulator 351
19/05/23 01:37:19 INFO ContextCleaner: Cleaned accumulator 411
19/05/23 01:37:19 INFO ContextCleaner: Cleaned shuffle 2
19/05/23 01:37:19 INFO ContextCleaner: Cleaned accumulator 357
19/05/23 01:37:19 INFO ContextCleaner: Cleaned accumulator 376
19/05/23 01:37:19 INFO ContextCleaner: Cleaned accumulator 395
19/05/23 01:37:19 INFO ContextCleaner: Cleaned accumulator 414
19/05/23 01:37:19 INFO ContextCleaner: Cleaned accumulator 410
19/05/23 01:37:19 INFO ContextCleaner: Cleaned accumulator 393
19/05/23 01:37:19 INFO ContextCleaner: Cleaned accumulator 417
19/05/23 01:37:19 INFO ContextCleaner: Cleaned accumulator 386
19/05/23 01:37:19 INFO ContextCleaner: Cleaned accumulator 380
19/05/23 01:37:19 INFO ContextCleaner: Cleaned accumulator 415
19/05/23 01:37:19 INFO Executor: Finished task 0.0 in stage 8.0 (TID 13). 1967 bytes result sent to driver
19/05/23 01:37:19 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 16, localhost, executor driver, partition 3, PROCESS_LOCAL, 7935 bytes)
19/05/23 01:37:19 INFO Executor: Running task 3.0 in stage 8.0 (TID 16)
19/05/23 01:37:19 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 13) in 1160 ms on localhost (executor driver) (2/4)
19/05/23 01:37:19 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-002/part-00000, range: 6305147-8415991, partition values: [empty row]
19/05/23 01:37:19 INFO Executor: Finished task 2.0 in stage 8.0 (TID 15). 1967 bytes result sent to driver
19/05/23 01:37:19 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 15) in 1121 ms on localhost (executor driver) (3/4)
19/05/23 01:37:19 INFO Executor: Finished task 3.0 in stage 8.0 (TID 16). 1924 bytes result sent to driver
19/05/23 01:37:19 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 16) in 384 ms on localhost (executor driver) (4/4)
19/05/23 01:37:19 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/05/23 01:37:19 INFO DAGScheduler: ShuffleMapStage 8 (count at LoadTransactionTest.scala:46) finished in 1.561 s
19/05/23 01:37:19 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:19 INFO DAGScheduler: running: Set()
19/05/23 01:37:19 INFO DAGScheduler: waiting: Set(ResultStage 9)
19/05/23 01:37:19 INFO DAGScheduler: failed: Set()
19/05/23 01:37:19 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[37] at count at LoadTransactionTest.scala:46), which has no missing parents
19/05/23 01:37:19 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 8.5 KB, free 911.5 MB)
19/05/23 01:37:19 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.4 KB, free 911.5 MB)
19/05/23 01:37:19 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on dataengineering:33505 (size: 4.4 KB, free: 912.2 MB)
19/05/23 01:37:19 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[37] at count at LoadTransactionTest.scala:46) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:19 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/05/23 01:37:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 17, localhost, executor driver, partition 0, ANY, 7246 bytes)
19/05/23 01:37:19 INFO Executor: Running task 0.0 in stage 9.0 (TID 17)
19/05/23 01:37:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
19/05/23 01:37:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/05/23 01:37:19 INFO Executor: Finished task 0.0 in stage 9.0 (TID 17). 1792 bytes result sent to driver
19/05/23 01:37:19 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 17) in 9 ms on localhost (executor driver) (1/1)
19/05/23 01:37:19 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/05/23 01:37:19 INFO DAGScheduler: ResultStage 9 (count at LoadTransactionTest.scala:46) finished in 0.015 s
19/05/23 01:37:19 INFO DAGScheduler: Job 5 finished: count at LoadTransactionTest.scala:46, took 1.584719 s
- Sanitize DataFrame by removing records with vendor prefix (1 second, 977 milliseconds)
19/05/23 01:37:19 INFO FileSourceStrategy: Pruning directories with: 
19/05/23 01:37:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(credit_card_number#30L),AtLeastNNulls(n, credit_card_number#30L,ipv4#31,state#32),NOT cast(credit_card_number#30L as string) RLIKE ^(34|37|2131|1800|51|52|54|55|222%|4|5018|5020|5038|56##|300|301|304|305|36|38|6011|65|35)(.*)+$
19/05/23 01:37:19 INFO FileSourceStrategy: Output Data Schema: struct<credit_card_number: bigint, ipv4: string, state: string ... 1 more fields>
19/05/23 01:37:19 INFO FileSourceScanExec: Pushed Filters: IsNotNull(credit_card_number)
19/05/23 01:37:19 INFO FileSourceStrategy: Pruning directories with: 
19/05/23 01:37:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(credit_card_number#50L),AtLeastNNulls(n, credit_card_number#50L,ipv4#51,state#52),NOT cast(credit_card_number#50L as string) RLIKE ^(34|37|2131|1800|51|52|54|55|222%|4|5018|5020|5038|56##|300|301|304|305|36|38|6011|65|35)(.*)+$
19/05/23 01:37:19 INFO FileSourceStrategy: Output Data Schema: struct<credit_card_number: bigint, ipv4: string, state: string ... 1 more fields>
19/05/23 01:37:19 INFO FileSourceScanExec: Pushed Filters: IsNotNull(credit_card_number)
19/05/23 01:37:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/05/23 01:37:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/05/23 01:37:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/05/23 01:37:19 INFO CodeGenerator: Code generated in 45.1439 ms
19/05/23 01:37:19 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 338.5 KB, free 911.2 MB)
19/05/23 01:37:19 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 28.6 KB, free 911.2 MB)
19/05/23 01:37:19 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on dataengineering:33505 (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:19 INFO SparkContext: Created broadcast 18 from csv at LoadTransactionTest.scala:22
19/05/23 01:37:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6305133 bytes, open cost is considered as scanning 4194304 bytes.
19/05/23 01:37:19 INFO CodeGenerator: Code generated in 36.8718 ms
19/05/23 01:37:19 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 338.5 KB, free 910.9 MB)
19/05/23 01:37:19 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 28.6 KB, free 910.8 MB)
19/05/23 01:37:19 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on dataengineering:33505 (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:19 INFO SparkContext: Created broadcast 19 from csv at LoadTransactionTest.scala:22
19/05/23 01:37:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6305147 bytes, open cost is considered as scanning 4194304 bytes.
19/05/23 01:37:19 INFO SparkContext: Starting job: csv at LoadTransactionTest.scala:22
19/05/23 01:37:19 INFO DAGScheduler: Registering RDD 43 (csv at LoadTransactionTest.scala:22)
19/05/23 01:37:19 INFO DAGScheduler: Got job 6 (csv at LoadTransactionTest.scala:22) with 1 output partitions
19/05/23 01:37:19 INFO DAGScheduler: Final stage: ResultStage 11 (csv at LoadTransactionTest.scala:22)
19/05/23 01:37:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
19/05/23 01:37:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
19/05/23 01:37:19 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[43] at csv at LoadTransactionTest.scala:22), which has no missing parents
19/05/23 01:37:19 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 19.6 KB, free 910.8 MB)
19/05/23 01:37:19 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.8 MB)
19/05/23 01:37:19 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on dataengineering:33505 (size: 8.1 KB, free: 912.2 MB)
19/05/23 01:37:19 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:19 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[43] at csv at LoadTransactionTest.scala:22) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/05/23 01:37:19 INFO TaskSchedulerImpl: Adding task set 10.0 with 4 tasks
19/05/23 01:37:19 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 7935 bytes)
19/05/23 01:37:19 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 19, localhost, executor driver, partition 1, PROCESS_LOCAL, 7935 bytes)
19/05/23 01:37:19 INFO Executor: Running task 0.0 in stage 10.0 (TID 18)
19/05/23 01:37:19 INFO Executor: Running task 1.0 in stage 10.0 (TID 19)
19/05/23 01:37:19 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-001/part-00000, range: 0-6305133, partition values: [empty row]
19/05/23 01:37:19 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-001/part-00000, range: 6305133-8415963, partition values: [empty row]
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 475
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 451
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 465
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 444
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 480
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 425
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 491
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 452
19/05/23 01:37:20 INFO BlockManagerInfo: Removed broadcast_16_piece0 on dataengineering:33505 in memory (size: 8.7 KB, free: 912.2 MB)
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 426
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 439
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 483
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 476
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 442
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 443
19/05/23 01:37:20 INFO BlockManagerInfo: Removed broadcast_15_piece0 on dataengineering:33505 in memory (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 428
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 423
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 430
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 462
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 484
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 458
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 441
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 489
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 466
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 449
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 470
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 482
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 479
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 492
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 429
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 445
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 437
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 421
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 424
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 493
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 490
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 457
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 473
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 432
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 433
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 461
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 468
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 488
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 471
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 435
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 459
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 453
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 467
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 456
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 463
19/05/23 01:37:20 INFO BlockManagerInfo: Removed broadcast_14_piece0 on dataengineering:33505 in memory (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 477
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 450
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 427
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 448
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 434
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 422
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 472
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 478
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 486
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 481
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 420
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 440
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 419
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 487
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 455
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 446
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 460
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 438
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 474
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 469
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 431
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 454
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 485
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 436
19/05/23 01:37:20 INFO BlockManagerInfo: Removed broadcast_17_piece0 on dataengineering:33505 in memory (size: 4.4 KB, free: 912.2 MB)
19/05/23 01:37:20 INFO ContextCleaner: Cleaned shuffle 3
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 447
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 464
19/05/23 01:37:20 INFO ContextCleaner: Cleaned accumulator 418
19/05/23 01:37:20 INFO Executor: Finished task 1.0 in stage 10.0 (TID 19). 1719 bytes result sent to driver
19/05/23 01:37:20 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 20, localhost, executor driver, partition 2, PROCESS_LOCAL, 7935 bytes)
19/05/23 01:37:20 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 19) in 640 ms on localhost (executor driver) (1/4)
19/05/23 01:37:20 INFO Executor: Running task 2.0 in stage 10.0 (TID 20)
19/05/23 01:37:20 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-002/part-00000, range: 0-6305147, partition values: [empty row]
19/05/23 01:37:21 INFO Executor: Finished task 0.0 in stage 10.0 (TID 18). 1719 bytes result sent to driver
19/05/23 01:37:21 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 21, localhost, executor driver, partition 3, PROCESS_LOCAL, 7935 bytes)
19/05/23 01:37:21 INFO Executor: Running task 3.0 in stage 10.0 (TID 21)
19/05/23 01:37:21 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 18) in 1230 ms on localhost (executor driver) (2/4)
19/05/23 01:37:21 INFO FileScanRDD: Reading File path: file:///tmp/spark-10c28abc-ef5f-4ff3-9481-bca6ddfa110ctransaction-002/part-00000, range: 6305147-8415991, partition values: [empty row]
19/05/23 01:37:21 INFO Executor: Finished task 3.0 in stage 10.0 (TID 21). 1676 bytes result sent to driver
19/05/23 01:37:21 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 21) in 281 ms on localhost (executor driver) (3/4)
19/05/23 01:37:21 INFO Executor: Finished task 2.0 in stage 10.0 (TID 20). 1719 bytes result sent to driver
19/05/23 01:37:21 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 20) in 1296 ms on localhost (executor driver) (4/4)
19/05/23 01:37:21 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/05/23 01:37:21 INFO DAGScheduler: ShuffleMapStage 10 (csv at LoadTransactionTest.scala:22) finished in 1.945 s
19/05/23 01:37:21 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:21 INFO DAGScheduler: running: Set()
19/05/23 01:37:21 INFO DAGScheduler: waiting: Set(ResultStage 11)
19/05/23 01:37:21 INFO DAGScheduler: failed: Set()
19/05/23 01:37:21 INFO DAGScheduler: Submitting ResultStage 11 (ShuffledRowRDD[44] at csv at LoadTransactionTest.scala:22), which has no missing parents
19/05/23 01:37:21 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 171.5 KB, free 911.4 MB)
19/05/23 01:37:21 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 62.3 KB, free 911.3 MB)
19/05/23 01:37:21 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on dataengineering:33505 (size: 62.3 KB, free: 912.2 MB)
19/05/23 01:37:21 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (ShuffledRowRDD[44] at csv at LoadTransactionTest.scala:22) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:21 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/05/23 01:37:21 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 22, localhost, executor driver, partition 0, ANY, 7246 bytes)
19/05/23 01:37:21 INFO Executor: Running task 0.0 in stage 11.0 (TID 22)
19/05/23 01:37:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
19/05/23 01:37:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/05/23 01:37:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/05/23 01:37:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/05/23 01:37:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/05/23 01:37:22 INFO FileOutputCommitter: Saved output of task 'attempt_20190523013719_0011_m_000000_22' to file:/data/txn/_temporary/0/task_20190523013719_0011_m_000000
19/05/23 01:37:22 INFO SparkHadoopMapRedUtil: attempt_20190523013719_0011_m_000000_22: Committed
19/05/23 01:37:22 INFO Executor: Finished task 0.0 in stage 11.0 (TID 22). 2301 bytes result sent to driver
19/05/23 01:37:22 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 22) in 306 ms on localhost (executor driver) (1/1)
19/05/23 01:37:22 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/05/23 01:37:22 INFO DAGScheduler: ResultStage 11 (csv at LoadTransactionTest.scala:22) finished in 0.331 s
19/05/23 01:37:22 INFO DAGScheduler: Job 6 finished: csv at LoadTransactionTest.scala:22, took 2.283491 s
19/05/23 01:37:22 INFO FileFormatWriter: Write Job 40872f26-6ba8-45f9-aa72-619084311f1f committed.
19/05/23 01:37:22 INFO FileFormatWriter: Finished processing stats for write job 40872f26-6ba8-45f9-aa72-619084311f1f.
19/05/23 01:37:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/05/23 01:37:22 INFO MemoryStore: MemoryStore cleared
19/05/23 01:37:22 INFO BlockManager: BlockManager stopped
19/05/23 01:37:22 INFO BlockManagerMaster: BlockManagerMaster stopped
19/05/23 01:37:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/05/23 01:37:22 INFO SparkContext: Successfully stopped SparkContext
19/05/23 01:37:22 INFO SparkContext: Running Spark version 2.4.3
19/05/23 01:37:22 INFO SparkContext: Submitted application: dataengineering_test
19/05/23 01:37:22 INFO SparkContext: Spark configuration:
datanucleus.rdbms.datastoreAdapterClassName=org.datanucleus.store.rdbms.adapter.DerbyAdapter
hive.exec.dynamic.partition=true
hive.exec.dynamic.partition.mode=nonstrict
hive.metastore.uris=
javax.jdo.option.ConnectionURL=jdbc:derby:;databaseName=/tmp/spark-d83f8fbe-b96e-4725-8687-a5a353ccd023/metastore;create=true
spark.app.id=dataengineering.ReportingTest46825
spark.app.name=dataengineering_test
spark.logConf=true
spark.master=local[2]
spark.sql.catalogImplementation=hive
spark.sql.codegen.fallback=false
spark.sql.parquet.compression.codec=snappy
spark.sql.shuffle.partitions=1
spark.sql.streaming.checkpointLocation=/tmp/spark-d83f8fbe-b96e-4725-8687-a5a353ccd023
spark.sql.warehouse.dir=/tmp/spark-d83f8fbe-b96e-4725-8687-a5a353ccd023/warehouse
spark.ui.enabled=false
19/05/23 01:37:22 INFO SecurityManager: Changing view acls to: root
19/05/23 01:37:22 INFO SecurityManager: Changing modify acls to: root
19/05/23 01:37:22 INFO SecurityManager: Changing view acls groups to: 
19/05/23 01:37:22 INFO SecurityManager: Changing modify acls groups to: 
19/05/23 01:37:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
ReportingTest:
19/05/23 01:37:22 INFO Utils: Successfully started service 'sparkDriver' on port 44999.
19/05/23 01:37:22 INFO SparkEnv: Registering MapOutputTracker
19/05/23 01:37:22 INFO SparkEnv: Registering BlockManagerMaster
19/05/23 01:37:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/05/23 01:37:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/05/23 01:37:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f31fb855-c22d-4700-9255-249918f61789
19/05/23 01:37:22 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/05/23 01:37:22 INFO SparkEnv: Registering OutputCommitCoordinator
19/05/23 01:37:22 INFO Executor: Starting executor ID driver on host localhost
19/05/23 01:37:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46681.
19/05/23 01:37:22 INFO NettyBlockTransferService: Server created on dataengineering:46681
19/05/23 01:37:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/05/23 01:37:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, dataengineering, 46681, None)
19/05/23 01:37:22 INFO BlockManagerMasterEndpoint: Registering block manager dataengineering:46681 with 912.3 MB RAM, BlockManagerId(driver, dataengineering, 46681, None)
19/05/23 01:37:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, dataengineering, 46681, None)
19/05/23 01:37:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, dataengineering, 46681, None)
19/05/23 01:37:22 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('/tmp/spark-d83f8fbe-b96e-4725-8687-a5a353ccd023/warehouse').
19/05/23 01:37:22 INFO SharedState: Warehouse path is '/tmp/spark-d83f8fbe-b96e-4725-8687-a5a353ccd023/warehouse'.
19/05/23 01:37:22 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/05/23 01:37:22 INFO CodeGenerator: Code generated in 22.4521 ms
19/05/23 01:37:22 INFO CodeGenerator: Code generated in 34.3283 ms
19/05/23 01:37:22 INFO SparkContext: Starting job: count at ReportingTest.scala:50
19/05/23 01:37:22 INFO DAGScheduler: Registering RDD 9 (count at ReportingTest.scala:50)
19/05/23 01:37:22 INFO DAGScheduler: Got job 0 (count at ReportingTest.scala:50) with 1 output partitions
19/05/23 01:37:22 INFO DAGScheduler: Final stage: ResultStage 1 (count at ReportingTest.scala:50)
19/05/23 01:37:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
19/05/23 01:37:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
19/05/23 01:37:22 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[9] at count at ReportingTest.scala:50), which has no missing parents
19/05/23 01:37:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 18.8 KB, free 912.3 MB)
19/05/23 01:37:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.4 KB, free 912.3 MB)
19/05/23 01:37:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on dataengineering:46681 (size: 8.4 KB, free: 912.3 MB)
19/05/23 01:37:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[9] at count at ReportingTest.scala:50) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/05/23 01:37:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7158 bytes)
19/05/23 01:37:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/05/23 01:37:23 INFO JDBCRDD: closed connection
19/05/23 01:37:23 INFO MemoryStore: Block rdd_4_0 stored as values in memory (estimated size 29.7 KB, free 912.2 MB)
19/05/23 01:37:23 INFO BlockManagerInfo: Added rdd_4_0 in memory on dataengineering:46681 (size: 29.7 KB, free: 912.3 MB)
19/05/23 01:37:23 INFO CodeGenerator: Code generated in 23.9638 ms
19/05/23 01:37:23 INFO CodeGenerator: Code generated in 43.6495 ms
19/05/23 01:37:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1801 bytes result sent to driver
19/05/23 01:37:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 388 ms on localhost (executor driver) (1/1)
19/05/23 01:37:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/05/23 01:37:23 INFO DAGScheduler: ShuffleMapStage 0 (count at ReportingTest.scala:50) finished in 0.447 s
19/05/23 01:37:23 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:23 INFO DAGScheduler: running: Set()
19/05/23 01:37:23 INFO DAGScheduler: waiting: Set(ResultStage 1)
19/05/23 01:37:23 INFO DAGScheduler: failed: Set()
19/05/23 01:37:23 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[12] at count at ReportingTest.scala:50), which has no missing parents
19/05/23 01:37:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.5 KB, free 912.2 MB)
19/05/23 01:37:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 912.2 MB)
19/05/23 01:37:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on dataengineering:46681 (size: 4.4 KB, free: 912.3 MB)
19/05/23 01:37:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at count at ReportingTest.scala:50) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/05/23 01:37:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 7246 bytes)
19/05/23 01:37:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
- Load Fraud data from MySql table (754 milliseconds)
19/05/23 01:37:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/05/23 01:37:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1749 bytes result sent to driver
19/05/23 01:37:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 9 ms on localhost (executor driver) (1/1)
19/05/23 01:37:23 INFO DAGScheduler: ResultStage 1 (count at ReportingTest.scala:50) finished in 0.019 s
19/05/23 01:37:23 INFO DAGScheduler: Job 0 finished: count at ReportingTest.scala:50, took 0.479882 s
19/05/23 01:37:23 INFO FileSourceStrategy: Pruning directories with: 
19/05/23 01:37:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/05/23 01:37:23 INFO FileSourceStrategy: Post-Scan Filters: 
19/05/23 01:37:23 INFO FileSourceStrategy: Output Data Schema: struct<credit_card_number: bigint, ipv4: string, state: string ... 1 more fields>
19/05/23 01:37:23 INFO FileSourceScanExec: Pushed Filters: 
19/05/23 01:37:23 INFO CodeGenerator: Code generated in 15.7024 ms
19/05/23 01:37:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 338.1 KB, free 911.9 MB)
19/05/23 01:37:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 28.6 KB, free 911.9 MB)
19/05/23 01:37:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on dataengineering:46681 (size: 28.6 KB, free: 912.2 MB)
19/05/23 01:37:23 INFO SparkContext: Created broadcast 2 from count at ReportingTest.scala:55
19/05/23 01:37:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/05/23 01:37:23 INFO SparkContext: Starting job: count at ReportingTest.scala:55
19/05/23 01:37:23 INFO DAGScheduler: Registering RDD 20 (count at ReportingTest.scala:55)
19/05/23 01:37:23 INFO DAGScheduler: Got job 1 (count at ReportingTest.scala:55) with 1 output partitions
19/05/23 01:37:23 INFO DAGScheduler: Final stage: ResultStage 3 (count at ReportingTest.scala:55)
19/05/23 01:37:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
19/05/23 01:37:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
19/05/23 01:37:23 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[20] at count at ReportingTest.scala:55), which has no missing parents
19/05/23 01:37:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 20.0 KB, free 911.9 MB)
19/05/23 01:37:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.3 KB, free 911.8 MB)
19/05/23 01:37:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on dataengineering:46681 (size: 9.3 KB, free: 912.2 MB)
19/05/23 01:37:23 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[20] at count at ReportingTest.scala:55) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/05/23 01:37:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7819 bytes)
19/05/23 01:37:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/05/23 01:37:23 INFO FileScanRDD: Reading File path: file:///data/txn/part-00000-4e6dc815-3145-4acd-9c34-6c778d49a769-c000.csv, range: 0-1786414, partition values: [empty row]
19/05/23 01:37:23 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 1513.0 KB, free 910.4 MB)
19/05/23 01:37:23 INFO BlockManagerInfo: Added rdd_15_0 in memory on dataengineering:46681 (size: 1513.0 KB, free: 910.7 MB)
19/05/23 01:37:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1844 bytes result sent to driver
19/05/23 01:37:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 418 ms on localhost (executor driver) (1/1)
19/05/23 01:37:24 INFO DAGScheduler: ShuffleMapStage 2 (count at ReportingTest.scala:55) finished in 0.435 s
19/05/23 01:37:24 INFO DAGScheduler: looking for newly runnable stages
- Load sanitized Transaction file from filesystem (572 milliseconds)
19/05/23 01:37:24 INFO DAGScheduler: running: Set()
19/05/23 01:37:24 INFO DAGScheduler: waiting: Set(ResultStage 3)
19/05/23 01:37:24 INFO DAGScheduler: failed: Set()
19/05/23 01:37:24 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[23] at count at ReportingTest.scala:55), which has no missing parents
19/05/23 01:37:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.5 KB, free 910.4 MB)
19/05/23 01:37:24 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 910.4 MB)
19/05/23 01:37:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on dataengineering:46681 (size: 4.4 KB, free: 910.7 MB)
19/05/23 01:37:24 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[23] at count at ReportingTest.scala:55) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:24 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/05/23 01:37:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/05/23 01:37:24 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, ANY, 7246 bytes)
19/05/23 01:37:24 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/05/23 01:37:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/05/23 01:37:24 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1749 bytes result sent to driver
19/05/23 01:37:24 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 19 ms on localhost (executor driver) (1/1)
19/05/23 01:37:24 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/05/23 01:37:24 INFO DAGScheduler: ResultStage 3 (count at ReportingTest.scala:55) finished in 0.029 s
19/05/23 01:37:24 INFO DAGScheduler: Job 1 finished: count at ReportingTest.scala:55, took 0.470081 s
19/05/23 01:37:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
19/05/23 01:37:24 INFO SparkContext: Starting job: run at ThreadPoolExecutor.java:1149
19/05/23 01:37:24 INFO DAGScheduler: Got job 2 (run at ThreadPoolExecutor.java:1149) with 1 output partitions
19/05/23 01:37:24 INFO DAGScheduler: Final stage: ResultStage 4 (run at ThreadPoolExecutor.java:1149)
19/05/23 01:37:24 INFO DAGScheduler: Parents of final stage: List()
19/05/23 01:37:24 INFO DAGScheduler: Missing parents: List()
19/05/23 01:37:24 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[30] at run at ThreadPoolExecutor.java:1149), which has no missing parents
19/05/23 01:37:24 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 15.0 KB, free 910.3 MB)
19/05/23 01:37:24 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.1 KB, free 910.3 MB)
19/05/23 01:37:24 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on dataengineering:46681 (size: 7.1 KB, free: 910.7 MB)
19/05/23 01:37:24 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[30] at run at ThreadPoolExecutor.java:1149) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:24 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/05/23 01:37:24 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7169 bytes)
19/05/23 01:37:24 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/05/23 01:37:24 INFO BlockManager: Found block rdd_4_0 locally
19/05/23 01:37:24 INFO CodeGenerator: Code generated in 56.2909 ms
19/05/23 01:37:24 INFO CodeGenerator: Code generated in 102.2503 ms
19/05/23 01:37:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
19/05/23 01:37:24 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 24007 bytes result sent to driver
19/05/23 01:37:24 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 126 ms on localhost (executor driver) (1/1)
19/05/23 01:37:24 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/05/23 01:37:24 INFO DAGScheduler: ResultStage 4 (run at ThreadPoolExecutor.java:1149) finished in 0.142 s
19/05/23 01:37:24 INFO DAGScheduler: Job 2 finished: run at ThreadPoolExecutor.java:1149, took 0.146457 s
19/05/23 01:37:24 INFO CodeGenerator: Code generated in 23.9589 ms
19/05/23 01:37:24 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 16.0 MB, free 894.3 MB)
19/05/23 01:37:24 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 38.5 KB, free 894.3 MB)
19/05/23 01:37:24 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on dataengineering:46681 (size: 38.5 KB, free: 910.7 MB)
19/05/23 01:37:24 INFO SparkContext: Created broadcast 6 from run at ThreadPoolExecutor.java:1149
19/05/23 01:37:24 INFO CodeGenerator: Code generated in 48.0069 ms
19/05/23 01:37:24 INFO SparkContext: Starting job: count at DataFrameSuiteBase.scala:138
19/05/23 01:37:24 INFO DAGScheduler: Got job 3 (count at DataFrameSuiteBase.scala:138) with 2 output partitions
19/05/23 01:37:24 INFO DAGScheduler: Final stage: ResultStage 5 (count at DataFrameSuiteBase.scala:138)
19/05/23 01:37:24 INFO DAGScheduler: Parents of final stage: List()
19/05/23 01:37:24 INFO DAGScheduler: Missing parents: List()
19/05/23 01:37:24 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at rdd at DataFrameSuiteBase.scala:136), which has no missing parents
19/05/23 01:37:24 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.9 KB, free 894.3 MB)
19/05/23 01:37:24 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.8 KB, free 894.2 MB)
19/05/23 01:37:24 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on dataengineering:46681 (size: 5.8 KB, free: 910.7 MB)
19/05/23 01:37:24 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at rdd at DataFrameSuiteBase.scala:136) (first 15 tasks are for partitions Vector(0, 1))
19/05/23 01:37:24 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
19/05/23 01:37:24 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 7602 bytes)
19/05/23 01:37:24 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 7602 bytes)
19/05/23 01:37:24 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/05/23 01:37:24 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
19/05/23 01:37:24 INFO CodeGenerator: Code generated in 50.426 ms
19/05/23 01:37:24 INFO MemoryStore: Block rdd_26_1 stored as values in memory (estimated size 984.0 B, free 894.2 MB)
19/05/23 01:37:24 INFO BlockManagerInfo: Added rdd_26_1 in memory on dataengineering:46681 (size: 984.0 B, free: 910.7 MB)
19/05/23 01:37:24 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 975 bytes result sent to driver
19/05/23 01:37:24 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 115 ms on localhost (executor driver) (1/2)
19/05/23 01:37:24 INFO MemoryStore: Block rdd_26_0 stored as values in memory (estimated size 984.0 B, free 894.2 MB)
19/05/23 01:37:24 INFO BlockManagerInfo: Added rdd_26_0 in memory on dataengineering:46681 (size: 984.0 B, free: 910.7 MB)
19/05/23 01:37:24 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 975 bytes result sent to driver
19/05/23 01:37:24 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 123 ms on localhost (executor driver) (2/2)
19/05/23 01:37:24 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/05/23 01:37:24 INFO DAGScheduler: ResultStage 5 (count at DataFrameSuiteBase.scala:138) finished in 0.147 s
19/05/23 01:37:24 INFO DAGScheduler: Job 3 finished: count at DataFrameSuiteBase.scala:138, took 0.150553 s
19/05/23 01:37:24 INFO SparkContext: Starting job: count at DataFrameSuiteBase.scala:138
19/05/23 01:37:24 INFO DAGScheduler: Registering RDD 35 (rdd at DataFrameSuiteBase.scala:137)
19/05/23 01:37:24 INFO DAGScheduler: Got job 4 (count at DataFrameSuiteBase.scala:138) with 1 output partitions
19/05/23 01:37:24 INFO DAGScheduler: Final stage: ResultStage 7 (count at DataFrameSuiteBase.scala:138)
19/05/23 01:37:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
19/05/23 01:37:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
19/05/23 01:37:24 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[35] at rdd at DataFrameSuiteBase.scala:137), which has no missing parents
19/05/23 01:37:24 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 41.0 KB, free 894.2 MB)
19/05/23 01:37:24 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 17.8 KB, free 894.2 MB)
19/05/23 01:37:24 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on dataengineering:46681 (size: 17.8 KB, free: 910.7 MB)
19/05/23 01:37:24 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[35] at rdd at DataFrameSuiteBase.scala:137) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:24 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/05/23 01:37:24 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 7819 bytes)
19/05/23 01:37:24 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
19/05/23 01:37:24 INFO BlockManager: Found block rdd_15_0 locally
19/05/23 01:37:24 INFO CodeGenerator: Code generated in 8.5005 ms
19/05/23 01:37:24 INFO CodeGenerator: Code generated in 15.247 ms
19/05/23 01:37:24 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 2894 bytes result sent to driver
19/05/23 01:37:24 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 138 ms on localhost (executor driver) (1/1)
19/05/23 01:37:24 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/05/23 01:37:24 INFO DAGScheduler: ShuffleMapStage 6 (rdd at DataFrameSuiteBase.scala:137) finished in 0.148 s
19/05/23 01:37:24 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:24 INFO DAGScheduler: running: Set()
19/05/23 01:37:24 INFO DAGScheduler: waiting: Set(ResultStage 7)
19/05/23 01:37:24 INFO DAGScheduler: failed: Set()
19/05/23 01:37:24 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[39] at rdd at DataFrameSuiteBase.scala:137), which has no missing parents
19/05/23 01:37:24 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 39.9 KB, free 894.1 MB)
19/05/23 01:37:24 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 17.6 KB, free 894.1 MB)
19/05/23 01:37:24 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on dataengineering:46681 (size: 17.6 KB, free: 910.7 MB)
19/05/23 01:37:24 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[39] at rdd at DataFrameSuiteBase.scala:137) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:24 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/05/23 01:37:24 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8, localhost, executor driver, partition 0, ANY, 7246 bytes)
19/05/23 01:37:24 INFO Executor: Running task 0.0 in stage 7.0 (TID 8)
19/05/23 01:37:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/05/23 01:37:24 INFO MemoryStore: Block rdd_39_0 stored as values in memory (estimated size 1392.0 B, free 894.1 MB)
19/05/23 01:37:24 INFO BlockManagerInfo: Added rdd_39_0 in memory on dataengineering:46681 (size: 1392.0 B, free: 910.7 MB)
19/05/23 01:37:24 INFO Executor: Finished task 0.0 in stage 7.0 (TID 8). 3480 bytes result sent to driver
19/05/23 01:37:24 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 48 ms on localhost (executor driver) (1/1)
19/05/23 01:37:24 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/05/23 01:37:24 INFO DAGScheduler: ResultStage 7 (count at DataFrameSuiteBase.scala:138) finished in 0.056 s
19/05/23 01:37:24 INFO DAGScheduler: Job 4 finished: count at DataFrameSuiteBase.scala:138, took 0.211003 s
19/05/23 01:37:24 INFO SparkContext: Starting job: zipWithIndex at DataFrameSuiteBase.scala:160
19/05/23 01:37:24 INFO DAGScheduler: Got job 5 (zipWithIndex at DataFrameSuiteBase.scala:160) with 1 output partitions
19/05/23 01:37:24 INFO DAGScheduler: Final stage: ResultStage 8 (zipWithIndex at DataFrameSuiteBase.scala:160)
19/05/23 01:37:24 INFO DAGScheduler: Parents of final stage: List()
19/05/23 01:37:24 INFO DAGScheduler: Missing parents: List()
19/05/23 01:37:24 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[26] at rdd at DataFrameSuiteBase.scala:136), which has no missing parents
19/05/23 01:37:25 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 12.0 KB, free 894.1 MB)
19/05/23 01:37:25 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.9 KB, free 894.1 MB)
19/05/23 01:37:25 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on dataengineering:46681 (size: 5.9 KB, free: 910.6 MB)
19/05/23 01:37:25 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[26] at rdd at DataFrameSuiteBase.scala:136) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:25 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/05/23 01:37:25 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7602 bytes)
19/05/23 01:37:25 INFO Executor: Running task 0.0 in stage 8.0 (TID 9)
19/05/23 01:37:25 INFO BlockManager: Found block rdd_26_0 locally
19/05/23 01:37:25 INFO Executor: Finished task 0.0 in stage 8.0 (TID 9). 1061 bytes result sent to driver
19/05/23 01:37:25 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 9) in 7 ms on localhost (executor driver) (1/1)
19/05/23 01:37:25 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/05/23 01:37:25 INFO DAGScheduler: ResultStage 8 (zipWithIndex at DataFrameSuiteBase.scala:160) finished in 0.013 s
19/05/23 01:37:25 INFO DAGScheduler: Job 5 finished: zipWithIndex at DataFrameSuiteBase.scala:160, took 0.015893 s
19/05/23 01:37:25 INFO SparkContext: Starting job: take at DataFrameSuiteBase.scala:147
19/05/23 01:37:25 INFO DAGScheduler: Registering RDD 41 (map at DataFrameSuiteBase.scala:160)
19/05/23 01:37:25 INFO DAGScheduler: Registering RDD 43 (map at DataFrameSuiteBase.scala:160)
19/05/23 01:37:25 INFO DAGScheduler: Got job 6 (take at DataFrameSuiteBase.scala:147) with 1 output partitions
19/05/23 01:37:25 INFO DAGScheduler: Final stage: ResultStage 12 (take at DataFrameSuiteBase.scala:147)
19/05/23 01:37:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9, ShuffleMapStage 11)
19/05/23 01:37:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9, ShuffleMapStage 11)
19/05/23 01:37:25 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[41] at map at DataFrameSuiteBase.scala:160), which has no missing parents
19/05/23 01:37:25 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 12.8 KB, free 894.1 MB)
19/05/23 01:37:25 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.4 KB, free 894.1 MB)
19/05/23 01:37:25 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on dataengineering:46681 (size: 6.4 KB, free: 910.6 MB)
19/05/23 01:37:25 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[41] at map at DataFrameSuiteBase.scala:160) (first 15 tasks are for partitions Vector(0, 1))
19/05/23 01:37:25 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks
19/05/23 01:37:25 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 7701 bytes)
19/05/23 01:37:25 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 11, localhost, executor driver, partition 1, PROCESS_LOCAL, 7701 bytes)
19/05/23 01:37:25 INFO Executor: Running task 0.0 in stage 9.0 (TID 10)
19/05/23 01:37:25 INFO Executor: Running task 1.0 in stage 9.0 (TID 11)
19/05/23 01:37:25 INFO BlockManager: Found block rdd_26_0 locally
19/05/23 01:37:25 INFO BlockManager: Found block rdd_26_1 locally
19/05/23 01:37:25 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[43] at map at DataFrameSuiteBase.scala:160), which has no missing parents
19/05/23 01:37:25 INFO Executor: Finished task 0.0 in stage 9.0 (TID 10). 1214 bytes result sent to driver
19/05/23 01:37:25 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 40.3 KB, free 894.1 MB)
19/05/23 01:37:25 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 10) in 33 ms on localhost (executor driver) (1/2)
19/05/23 01:37:25 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 17.9 KB, free 894.0 MB)
19/05/23 01:37:25 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on dataengineering:46681 (size: 17.9 KB, free: 910.6 MB)
19/05/23 01:37:25 INFO Executor: Finished task 1.0 in stage 9.0 (TID 11). 1214 bytes result sent to driver
19/05/23 01:37:25 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 11) in 39 ms on localhost (executor driver) (2/2)
19/05/23 01:37:25 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/05/23 01:37:25 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[43] at map at DataFrameSuiteBase.scala:160) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:25 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/05/23 01:37:25 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 7345 bytes)
19/05/23 01:37:25 INFO Executor: Running task 0.0 in stage 11.0 (TID 12)
19/05/23 01:37:25 INFO DAGScheduler: ShuffleMapStage 9 (map at DataFrameSuiteBase.scala:160) finished in 0.053 s
19/05/23 01:37:25 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:25 INFO DAGScheduler: running: Set(ShuffleMapStage 11)
19/05/23 01:37:25 INFO DAGScheduler: waiting: Set(ResultStage 12)
19/05/23 01:37:25 INFO DAGScheduler: failed: Set()
19/05/23 01:37:25 INFO BlockManager: Found block rdd_39_0 locally
19/05/23 01:37:25 INFO Executor: Finished task 0.0 in stage 11.0 (TID 12). 3375 bytes result sent to driver
19/05/23 01:37:25 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 12) in 17 ms on localhost (executor driver) (1/1)
19/05/23 01:37:25 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/05/23 01:37:25 INFO DAGScheduler: ShuffleMapStage 11 (map at DataFrameSuiteBase.scala:160) finished in 0.040 s
19/05/23 01:37:25 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:25 INFO DAGScheduler: running: Set()
19/05/23 01:37:25 INFO DAGScheduler: waiting: Set(ResultStage 12)
19/05/23 01:37:25 INFO DAGScheduler: failed: Set()
19/05/23 01:37:25 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[47] at filter at DataFrameSuiteBase.scala:144), which has no missing parents
19/05/23 01:37:25 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 4.9 KB, free 894.0 MB)
19/05/23 01:37:25 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.7 KB, free 894.0 MB)
19/05/23 01:37:25 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on dataengineering:46681 (size: 2.7 KB, free: 910.6 MB)
19/05/23 01:37:25 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[47] at filter at DataFrameSuiteBase.scala:144) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:25 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/05/23 01:37:25 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 7204 bytes)
19/05/23 01:37:25 INFO Executor: Running task 0.0 in stage 12.0 (TID 13)
19/05/23 01:37:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
19/05/23 01:37:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/05/23 01:37:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/05/23 01:37:25 INFO Executor: Finished task 0.0 in stage 12.0 (TID 13). 1097 bytes result sent to driver
19/05/23 01:37:25 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 13) in 139 ms on localhost (executor driver) (1/1)
19/05/23 01:37:25 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/05/23 01:37:25 INFO DAGScheduler: ResultStage 12 (take at DataFrameSuiteBase.scala:147) finished in 0.144 s
19/05/23 01:37:25 INFO DAGScheduler: Job 6 finished: take at DataFrameSuiteBase.scala:147, took 0.213973 s
19/05/23 01:37:25 INFO SparkContext: Starting job: take at DataFrameSuiteBase.scala:147
19/05/23 01:37:25 INFO DAGScheduler: Got job 7 (take at DataFrameSuiteBase.scala:147) with 1 output partitions
19/05/23 01:37:25 INFO DAGScheduler: Final stage: ResultStage 16 (take at DataFrameSuiteBase.scala:147)
19/05/23 01:37:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15, ShuffleMapStage 13)
19/05/23 01:37:25 INFO DAGScheduler: Missing parents: List()
19/05/23 01:37:25 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[47] at filter at DataFrameSuiteBase.scala:144), which has no missing parents
19/05/23 01:37:25 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 4.9 KB, free 894.0 MB)
19/05/23 01:37:25 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.7 KB, free 894.0 MB)
19/05/23 01:37:25 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on dataengineering:46681 (size: 2.7 KB, free: 910.6 MB)
19/05/23 01:37:25 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[47] at filter at DataFrameSuiteBase.scala:144) (first 15 tasks are for partitions Vector(1))
19/05/23 01:37:25 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/05/23 01:37:25 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 14, localhost, executor driver, partition 1, PROCESS_LOCAL, 7204 bytes)
19/05/23 01:37:25 INFO Executor: Running task 0.0 in stage 16.0 (TID 14)
19/05/23 01:37:25 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
19/05/23 01:37:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/05/23 01:37:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/05/23 01:37:25 INFO Executor: Finished task 0.0 in stage 16.0 (TID 14). 1097 bytes result sent to driver
19/05/23 01:37:25 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 14) in 9 ms on localhost (executor driver) (1/1)
19/05/23 01:37:25 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/05/23 01:37:25 INFO DAGScheduler: ResultStage 16 (take at DataFrameSuiteBase.scala:147) finished in 0.014 s
19/05/23 01:37:25 INFO DAGScheduler: Job 7 finished: take at DataFrameSuiteBase.scala:147, took 0.016943 s
19/05/23 01:37:25 INFO MapPartitionsRDD: Removing RDD 26 from persistence list
19/05/23 01:37:25 INFO BlockManager: Removing RDD 26
19/05/23 01:37:25 INFO MapPartitionsRDD: Removing RDD 39 from persistence list
19/05/23 01:37:25 INFO BlockManager: Removing RDD 39
19/05/23 01:37:25 INFO CodeGenerator: Code generated in 44.8828 ms
19/05/23 01:37:25 INFO CodeGenerator: Code generated in 56.0027 ms
19/05/23 01:37:25 INFO SparkContext: Starting job: run at ThreadPoolExecutor.java:1149
19/05/23 01:37:25 INFO DAGScheduler: Got job 8 (run at ThreadPoolExecutor.java:1149) with 1 output partitions
19/05/23 01:37:25 INFO DAGScheduler: Final stage: ResultStage 17 (run at ThreadPoolExecutor.java:1149)
19/05/23 01:37:25 INFO DAGScheduler: Parents of final stage: List()
19/05/23 01:37:25 INFO DAGScheduler: Missing parents: List()
19/05/23 01:37:25 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[58] at run at ThreadPoolExecutor.java:1149), which has no missing parents
19/05/23 01:37:25 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 15.0 KB, free 894.0 MB)
19/05/23 01:37:25 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.1 KB, free 894.0 MB)
19/05/23 01:37:25 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on dataengineering:46681 (size: 7.1 KB, free: 910.6 MB)
19/05/23 01:37:25 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[58] at run at ThreadPoolExecutor.java:1149) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:25 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/05/23 01:37:25 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7169 bytes)
19/05/23 01:37:25 INFO Executor: Running task 0.0 in stage 17.0 (TID 15)
19/05/23 01:37:25 INFO BlockManager: Found block rdd_4_0 locally
19/05/23 01:37:25 INFO Executor: Finished task 0.0 in stage 17.0 (TID 15). 24050 bytes result sent to driver
19/05/23 01:37:25 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 15) in 11 ms on localhost (executor driver) (1/1)
19/05/23 01:37:25 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/05/23 01:37:25 INFO DAGScheduler: ResultStage 17 (run at ThreadPoolExecutor.java:1149) finished in 0.017 s
19/05/23 01:37:25 INFO DAGScheduler: Job 8 finished: run at ThreadPoolExecutor.java:1149, took 0.019458 s
19/05/23 01:37:25 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 16.0 MB, free 878.0 MB)
19/05/23 01:37:25 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 38.5 KB, free 877.9 MB)
19/05/23 01:37:25 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on dataengineering:46681 (size: 38.5 KB, free: 910.6 MB)
19/05/23 01:37:25 INFO SparkContext: Created broadcast 16 from run at ThreadPoolExecutor.java:1149
19/05/23 01:37:25 INFO CodeGenerator: Code generated in 46.3134 ms
19/05/23 01:37:25 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
19/05/23 01:37:26 INFO CodeGenerator: Code generated in 42.099 ms
19/05/23 01:37:26 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
19/05/23 01:37:26 INFO SparkContext: Starting job: count at DataFrameSuiteBase.scala:138
19/05/23 01:37:26 INFO DAGScheduler: Registering RDD 50 (rdd at DataFrameSuiteBase.scala:136)
19/05/23 01:37:26 INFO DAGScheduler: Got job 9 (count at DataFrameSuiteBase.scala:138) with 1 output partitions
19/05/23 01:37:26 INFO DAGScheduler: Final stage: ResultStage 19 (count at DataFrameSuiteBase.scala:138)
19/05/23 01:37:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
19/05/23 01:37:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
19/05/23 01:37:26 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[50] at rdd at DataFrameSuiteBase.scala:136), which has no missing parents
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 26.5 KB, free 877.9 MB)
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 12.0 KB, free 877.9 MB)
19/05/23 01:37:26 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on dataengineering:46681 (size: 12.0 KB, free: 910.6 MB)
19/05/23 01:37:26 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:26 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[50] at rdd at DataFrameSuiteBase.scala:136) (first 15 tasks are for partitions Vector(0, 1))
19/05/23 01:37:26 INFO TaskSchedulerImpl: Adding task set 18.0 with 2 tasks
19/05/23 01:37:26 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 7591 bytes)
19/05/23 01:37:26 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 17, localhost, executor driver, partition 1, PROCESS_LOCAL, 7591 bytes)
19/05/23 01:37:26 INFO Executor: Running task 1.0 in stage 18.0 (TID 17)
19/05/23 01:37:26 INFO Executor: Running task 0.0 in stage 18.0 (TID 16)
19/05/23 01:37:26 INFO CodeGenerator: Code generated in 21.2449 ms
19/05/23 01:37:26 INFO CodeGenerator: Code generated in 50.6873 ms
19/05/23 01:37:26 INFO CodeGenerator: Code generated in 41.6626 ms
19/05/23 01:37:26 INFO CodeGenerator: Code generated in 27.2653 ms
19/05/23 01:37:26 INFO Executor: Finished task 0.0 in stage 18.0 (TID 16). 1838 bytes result sent to driver
19/05/23 01:37:26 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 16) in 360 ms on localhost (executor driver) (1/2)
19/05/23 01:37:26 INFO Executor: Finished task 1.0 in stage 18.0 (TID 17). 1838 bytes result sent to driver
19/05/23 01:37:26 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 17) in 363 ms on localhost (executor driver) (2/2)
19/05/23 01:37:26 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/05/23 01:37:26 INFO DAGScheduler: ShuffleMapStage 18 (rdd at DataFrameSuiteBase.scala:136) finished in 0.369 s
19/05/23 01:37:26 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:26 INFO DAGScheduler: running: Set()
19/05/23 01:37:26 INFO DAGScheduler: waiting: Set(ResultStage 19)
19/05/23 01:37:26 INFO DAGScheduler: failed: Set()
19/05/23 01:37:26 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[54] at rdd at DataFrameSuiteBase.scala:136), which has no missing parents
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 24.5 KB, free 877.9 MB)
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 11.2 KB, free 877.9 MB)
19/05/23 01:37:26 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on dataengineering:46681 (size: 11.2 KB, free: 910.6 MB)
19/05/23 01:37:26 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[54] at rdd at DataFrameSuiteBase.scala:136) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:26 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/05/23 01:37:26 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 18, localhost, executor driver, partition 0, ANY, 7246 bytes)
19/05/23 01:37:26 INFO Executor: Running task 0.0 in stage 19.0 (TID 18)
19/05/23 01:37:26 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
19/05/23 01:37:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/05/23 01:37:26 INFO CodeGenerator: Code generated in 10.7926 ms
19/05/23 01:37:26 INFO MemoryStore: Block rdd_54_0 stored as values in memory (estimated size 912.0 B, free 877.9 MB)
19/05/23 01:37:26 INFO BlockManagerInfo: Added rdd_54_0 in memory on dataengineering:46681 (size: 912.0 B, free: 910.6 MB)
19/05/23 01:37:26 INFO Executor: Finished task 0.0 in stage 19.0 (TID 18). 2467 bytes result sent to driver
19/05/23 01:37:26 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 18) in 52 ms on localhost (executor driver) (1/1)
19/05/23 01:37:26 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/05/23 01:37:26 INFO DAGScheduler: ResultStage 19 (count at DataFrameSuiteBase.scala:138) finished in 0.059 s
19/05/23 01:37:26 INFO DAGScheduler: Job 9 finished: count at DataFrameSuiteBase.scala:138, took 0.433950 s
19/05/23 01:37:26 INFO SparkContext: Starting job: count at DataFrameSuiteBase.scala:138
19/05/23 01:37:26 INFO DAGScheduler: Registering RDD 63 (rdd at DataFrameSuiteBase.scala:137)
19/05/23 01:37:26 INFO DAGScheduler: Registering RDD 66 (rdd at DataFrameSuiteBase.scala:137)
19/05/23 01:37:26 INFO DAGScheduler: Got job 10 (count at DataFrameSuiteBase.scala:138) with 1 output partitions
19/05/23 01:37:26 INFO DAGScheduler: Final stage: ResultStage 22 (count at DataFrameSuiteBase.scala:138)
19/05/23 01:37:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
19/05/23 01:37:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
19/05/23 01:37:26 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[63] at rdd at DataFrameSuiteBase.scala:137), which has no missing parents
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 41.0 KB, free 877.8 MB)
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 17.8 KB, free 877.8 MB)
19/05/23 01:37:26 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on dataengineering:46681 (size: 17.8 KB, free: 910.5 MB)
19/05/23 01:37:26 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[63] at rdd at DataFrameSuiteBase.scala:137) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:26 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/05/23 01:37:26 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 7819 bytes)
19/05/23 01:37:26 INFO Executor: Running task 0.0 in stage 20.0 (TID 19)
19/05/23 01:37:26 INFO BlockManager: Found block rdd_15_0 locally
19/05/23 01:37:26 INFO Executor: Finished task 0.0 in stage 20.0 (TID 19). 2894 bytes result sent to driver
19/05/23 01:37:26 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 19) in 40 ms on localhost (executor driver) (1/1)
19/05/23 01:37:26 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/05/23 01:37:26 INFO DAGScheduler: ShuffleMapStage 20 (rdd at DataFrameSuiteBase.scala:137) finished in 0.045 s
19/05/23 01:37:26 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:26 INFO DAGScheduler: running: Set()
19/05/23 01:37:26 INFO DAGScheduler: waiting: Set(ShuffleMapStage 21, ResultStage 22)
19/05/23 01:37:26 INFO DAGScheduler: failed: Set()
19/05/23 01:37:26 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[66] at rdd at DataFrameSuiteBase.scala:137), which has no missing parents
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 48.9 KB, free 877.8 MB)
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 21.0 KB, free 877.7 MB)
19/05/23 01:37:26 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on dataengineering:46681 (size: 21.0 KB, free: 910.5 MB)
19/05/23 01:37:26 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[66] at rdd at DataFrameSuiteBase.scala:137) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:26 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/05/23 01:37:26 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 20, localhost, executor driver, partition 0, ANY, 7235 bytes)
19/05/23 01:37:26 INFO Executor: Running task 0.0 in stage 21.0 (TID 20)
19/05/23 01:37:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/05/23 01:37:26 INFO Executor: Finished task 0.0 in stage 21.0 (TID 20). 4156 bytes result sent to driver
19/05/23 01:37:26 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 20) in 22 ms on localhost (executor driver) (1/1)
19/05/23 01:37:26 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/05/23 01:37:26 INFO DAGScheduler: ShuffleMapStage 21 (rdd at DataFrameSuiteBase.scala:137) finished in 0.029 s
19/05/23 01:37:26 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:26 INFO DAGScheduler: running: Set()
19/05/23 01:37:26 INFO DAGScheduler: waiting: Set(ResultStage 22)
19/05/23 01:37:26 INFO DAGScheduler: failed: Set()
19/05/23 01:37:26 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[70] at rdd at DataFrameSuiteBase.scala:137), which has no missing parents
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 42.7 KB, free 877.7 MB)
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 19.0 KB, free 877.7 MB)
19/05/23 01:37:26 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on dataengineering:46681 (size: 19.0 KB, free: 910.5 MB)
19/05/23 01:37:26 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[70] at rdd at DataFrameSuiteBase.scala:137) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:26 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/05/23 01:37:26 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 21, localhost, executor driver, partition 0, ANY, 7246 bytes)
19/05/23 01:37:26 INFO Executor: Running task 0.0 in stage 22.0 (TID 21)
19/05/23 01:37:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/05/23 01:37:26 INFO MemoryStore: Block rdd_70_0 stored as values in memory (estimated size 912.0 B, free 877.7 MB)
19/05/23 01:37:26 INFO BlockManagerInfo: Added rdd_70_0 in memory on dataengineering:46681 (size: 912.0 B, free: 910.5 MB)
19/05/23 01:37:26 INFO Executor: Finished task 0.0 in stage 22.0 (TID 21). 4527 bytes result sent to driver
19/05/23 01:37:26 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 21) in 24 ms on localhost (executor driver) (1/1)
19/05/23 01:37:26 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/05/23 01:37:26 INFO DAGScheduler: ResultStage 22 (count at DataFrameSuiteBase.scala:138) finished in 0.038 s
19/05/23 01:37:26 INFO DAGScheduler: Job 10 finished: count at DataFrameSuiteBase.scala:138, took 0.120484 s
19/05/23 01:37:26 INFO SparkContext: Starting job: take at DataFrameSuiteBase.scala:147
19/05/23 01:37:26 INFO DAGScheduler: Registering RDD 74 (map at DataFrameSuiteBase.scala:160)
19/05/23 01:37:26 INFO DAGScheduler: Registering RDD 72 (map at DataFrameSuiteBase.scala:160)
19/05/23 01:37:26 INFO DAGScheduler: Got job 11 (take at DataFrameSuiteBase.scala:147) with 1 output partitions
19/05/23 01:37:26 INFO DAGScheduler: Final stage: ResultStage 28 (take at DataFrameSuiteBase.scala:147)
19/05/23 01:37:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27, ShuffleMapStage 25)
19/05/23 01:37:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27, ShuffleMapStage 25)
19/05/23 01:37:26 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[74] at map at DataFrameSuiteBase.scala:160), which has no missing parents
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 43.0 KB, free 877.6 MB)
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 19.3 KB, free 877.6 MB)
19/05/23 01:37:26 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on dataengineering:46681 (size: 19.3 KB, free: 910.5 MB)
19/05/23 01:37:26 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[74] at map at DataFrameSuiteBase.scala:160) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:26 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/05/23 01:37:26 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 7345 bytes)
19/05/23 01:37:26 INFO Executor: Running task 0.0 in stage 25.0 (TID 22)
19/05/23 01:37:26 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[72] at map at DataFrameSuiteBase.scala:160), which has no missing parents
19/05/23 01:37:26 INFO BlockManager: Found block rdd_70_0 locally
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 24.8 KB, free 877.6 MB)
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 11.4 KB, free 877.6 MB)
19/05/23 01:37:26 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on dataengineering:46681 (size: 11.4 KB, free: 910.5 MB)
19/05/23 01:37:26 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[72] at map at DataFrameSuiteBase.scala:160) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:26 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
19/05/23 01:37:26 INFO Executor: Finished task 0.0 in stage 25.0 (TID 22). 4421 bytes result sent to driver
19/05/23 01:37:26 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 7345 bytes)
19/05/23 01:37:26 INFO Executor: Running task 0.0 in stage 27.0 (TID 23)
19/05/23 01:37:26 INFO BlockManager: Found block rdd_54_0 locally
19/05/23 01:37:26 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 22) in 37 ms on localhost (executor driver) (1/1)
19/05/23 01:37:26 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/05/23 01:37:26 INFO Executor: Finished task 0.0 in stage 27.0 (TID 23). 2361 bytes result sent to driver
19/05/23 01:37:26 INFO DAGScheduler: ShuffleMapStage 25 (map at DataFrameSuiteBase.scala:160) finished in 0.050 s
19/05/23 01:37:26 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 23) in 19 ms on localhost (executor driver) (1/1)
19/05/23 01:37:26 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/05/23 01:37:26 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:26 INFO DAGScheduler: running: Set(ShuffleMapStage 27)
19/05/23 01:37:26 INFO DAGScheduler: waiting: Set(ResultStage 28)
19/05/23 01:37:26 INFO DAGScheduler: failed: Set()
19/05/23 01:37:26 INFO DAGScheduler: ShuffleMapStage 27 (map at DataFrameSuiteBase.scala:160) finished in 0.035 s
19/05/23 01:37:26 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:26 INFO DAGScheduler: running: Set()
19/05/23 01:37:26 INFO DAGScheduler: waiting: Set(ResultStage 28)
19/05/23 01:37:26 INFO DAGScheduler: failed: Set()
19/05/23 01:37:26 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[78] at filter at DataFrameSuiteBase.scala:144), which has no missing parents
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 4.9 KB, free 877.6 MB)
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.7 KB, free 877.6 MB)
19/05/23 01:37:26 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on dataengineering:46681 (size: 2.7 KB, free: 910.5 MB)
19/05/23 01:37:26 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[78] at filter at DataFrameSuiteBase.scala:144) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:26 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/05/23 01:37:26 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 7204 bytes)
19/05/23 01:37:26 INFO Executor: Running task 0.0 in stage 28.0 (TID 24)
19/05/23 01:37:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/05/23 01:37:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/05/23 01:37:26 INFO Executor: Finished task 0.0 in stage 28.0 (TID 24). 1097 bytes result sent to driver
19/05/23 01:37:26 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 24) in 22 ms on localhost (executor driver) (1/1)
19/05/23 01:37:26 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/05/23 01:37:26 INFO DAGScheduler: ResultStage 28 (take at DataFrameSuiteBase.scala:147) finished in 0.031 s
19/05/23 01:37:26 INFO DAGScheduler: Job 11 finished: take at DataFrameSuiteBase.scala:147, took 0.129712 s
19/05/23 01:37:26 INFO MapPartitionsRDD: Removing RDD 54 from persistence list
19/05/23 01:37:26 INFO BlockManager: Removing RDD 54
19/05/23 01:37:26 INFO MapPartitionsRDD: Removing RDD 70 from persistence list
19/05/23 01:37:26 INFO BlockManager: Removing RDD 70
19/05/23 01:37:26 INFO Spark: ########## Writing DataFrame into /data/reports/fraud_txn_per_state
19/05/23 01:37:26 INFO SparkContext: Starting job: run at ThreadPoolExecutor.java:1149
19/05/23 01:37:26 INFO DAGScheduler: Got job 12 (run at ThreadPoolExecutor.java:1149) with 1 output partitions
19/05/23 01:37:26 INFO DAGScheduler: Final stage: ResultStage 29 (run at ThreadPoolExecutor.java:1149)
19/05/23 01:37:26 INFO DAGScheduler: Parents of final stage: List()
19/05/23 01:37:26 INFO DAGScheduler: Missing parents: List()
19/05/23 01:37:26 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[82] at run at ThreadPoolExecutor.java:1149), which has no missing parents
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 15.0 KB, free 877.6 MB)
19/05/23 01:37:26 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 7.1 KB, free 877.6 MB)
19/05/23 01:37:26 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on dataengineering:46681 (size: 7.1 KB, free: 910.5 MB)
19/05/23 01:37:26 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[82] at run at ThreadPoolExecutor.java:1149) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:26 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/05/23 01:37:26 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 7169 bytes)
19/05/23 01:37:26 INFO Executor: Running task 0.0 in stage 29.0 (TID 25)
19/05/23 01:37:26 INFO BlockManager: Found block rdd_4_0 locally
19/05/23 01:37:26 INFO Executor: Finished task 0.0 in stage 29.0 (TID 25). 24007 bytes result sent to driver
19/05/23 01:37:27 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 25) in 9 ms on localhost (executor driver) (1/1)
19/05/23 01:37:27 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/05/23 01:37:27 INFO DAGScheduler: ResultStage 29 (run at ThreadPoolExecutor.java:1149) finished in 0.024 s
19/05/23 01:37:27 INFO DAGScheduler: Job 12 finished: run at ThreadPoolExecutor.java:1149, took 0.047692 s
19/05/23 01:37:27 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 16.0 MB, free 861.5 MB)
19/05/23 01:37:27 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 38.5 KB, free 861.5 MB)
19/05/23 01:37:27 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on dataengineering:46681 (size: 38.5 KB, free: 910.4 MB)
19/05/23 01:37:27 INFO SparkContext: Created broadcast 26 from run at ThreadPoolExecutor.java:1149
19/05/23 01:37:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/05/23 01:37:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/05/23 01:37:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/05/23 01:37:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
19/05/23 01:37:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
19/05/23 01:37:27 INFO SparkContext: Starting job: json at Spark.scala:57
19/05/23 01:37:27 INFO DAGScheduler: Registering RDD 87 (json at Spark.scala:57)
19/05/23 01:37:27 INFO DAGScheduler: Registering RDD 90 (json at Spark.scala:57)
19/05/23 01:37:27 INFO DAGScheduler: Registering RDD 93 (json at Spark.scala:57)
19/05/23 01:37:27 INFO DAGScheduler: Got job 13 (json at Spark.scala:57) with 1 output partitions
19/05/23 01:37:27 INFO DAGScheduler: Final stage: ResultStage 33 (json at Spark.scala:57)
19/05/23 01:37:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
19/05/23 01:37:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)
19/05/23 01:37:27 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[87] at json at Spark.scala:57), which has no missing parents
19/05/23 01:37:27 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 41.0 KB, free 861.4 MB)
19/05/23 01:37:27 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 17.8 KB, free 861.4 MB)
19/05/23 01:37:27 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on dataengineering:46681 (size: 17.8 KB, free: 910.4 MB)
19/05/23 01:37:27 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[87] at json at Spark.scala:57) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:27 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
19/05/23 01:37:27 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 7819 bytes)
19/05/23 01:37:27 INFO Executor: Running task 0.0 in stage 30.0 (TID 26)
19/05/23 01:37:27 INFO BlockManager: Found block rdd_15_0 locally
19/05/23 01:37:27 INFO Executor: Finished task 0.0 in stage 30.0 (TID 26). 2894 bytes result sent to driver
19/05/23 01:37:27 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 26) in 38 ms on localhost (executor driver) (1/1)
19/05/23 01:37:27 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/05/23 01:37:27 INFO DAGScheduler: ShuffleMapStage 30 (json at Spark.scala:57) finished in 0.048 s
19/05/23 01:37:27 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:27 INFO DAGScheduler: running: Set()
19/05/23 01:37:27 INFO DAGScheduler: waiting: Set(ResultStage 33, ShuffleMapStage 31, ShuffleMapStage 32)
19/05/23 01:37:27 INFO DAGScheduler: failed: Set()
19/05/23 01:37:27 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[90] at json at Spark.scala:57), which has no missing parents
19/05/23 01:37:27 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 48.9 KB, free 861.4 MB)
19/05/23 01:37:27 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 20.9 KB, free 861.4 MB)
19/05/23 01:37:27 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on dataengineering:46681 (size: 20.9 KB, free: 910.4 MB)
19/05/23 01:37:27 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[90] at json at Spark.scala:57) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:27 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/05/23 01:37:27 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 27, localhost, executor driver, partition 0, ANY, 7235 bytes)
19/05/23 01:37:27 INFO Executor: Running task 0.0 in stage 31.0 (TID 27)
19/05/23 01:37:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/05/23 01:37:27 INFO Executor: Finished task 0.0 in stage 31.0 (TID 27). 4199 bytes result sent to driver
19/05/23 01:37:27 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 27) in 28 ms on localhost (executor driver) (1/1)
19/05/23 01:37:27 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/05/23 01:37:27 INFO DAGScheduler: ShuffleMapStage 31 (json at Spark.scala:57) finished in 0.047 s
19/05/23 01:37:27 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:27 INFO DAGScheduler: running: Set()
19/05/23 01:37:27 INFO DAGScheduler: waiting: Set(ResultStage 33, ShuffleMapStage 32)
19/05/23 01:37:27 INFO DAGScheduler: failed: Set()
19/05/23 01:37:27 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[93] at json at Spark.scala:57), which has no missing parents
19/05/23 01:37:27 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 41.4 KB, free 861.3 MB)
19/05/23 01:37:27 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 18.5 KB, free 861.3 MB)
19/05/23 01:37:27 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on dataengineering:46681 (size: 18.5 KB, free: 910.4 MB)
19/05/23 01:37:27 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[93] at json at Spark.scala:57) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:27 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/05/23 01:37:27 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 28, localhost, executor driver, partition 0, ANY, 7235 bytes)
19/05/23 01:37:27 INFO Executor: Running task 0.0 in stage 32.0 (TID 28)
19/05/23 01:37:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/05/23 01:37:27 INFO Executor: Finished task 0.0 in stage 32.0 (TID 28). 4770 bytes result sent to driver
19/05/23 01:37:27 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 28) in 14 ms on localhost (executor driver) (1/1)
19/05/23 01:37:27 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/05/23 01:37:27 INFO DAGScheduler: ShuffleMapStage 32 (json at Spark.scala:57) finished in 0.022 s
19/05/23 01:37:27 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:27 INFO DAGScheduler: running: Set()
19/05/23 01:37:27 INFO DAGScheduler: waiting: Set(ResultStage 33)
19/05/23 01:37:27 INFO DAGScheduler: failed: Set()
19/05/23 01:37:27 INFO DAGScheduler: Submitting ResultStage 33 (ShuffledRowRDD[94] at json at Spark.scala:57), which has no missing parents
19/05/23 01:37:27 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 171.2 KB, free 861.1 MB)
19/05/23 01:37:27 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 62.3 KB, free 861.1 MB)
19/05/23 01:37:27 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on dataengineering:46681 (size: 62.3 KB, free: 910.3 MB)
19/05/23 01:37:27 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (ShuffledRowRDD[94] at json at Spark.scala:57) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:27 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/05/23 01:37:27 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 29, localhost, executor driver, partition 0, ANY, 7246 bytes)
19/05/23 01:37:27 INFO Executor: Running task 0.0 in stage 33.0 (TID 29)
19/05/23 01:37:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/05/23 01:37:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/05/23 01:37:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/05/23 01:37:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/05/23 01:37:27 INFO FileOutputCommitter: Saved output of task 'attempt_20190523013727_0033_m_000000_29' to file:/data/reports/fraud_txn_per_state/_temporary/0/task_20190523013727_0033_m_000000
19/05/23 01:37:27 INFO SparkHadoopMapRedUtil: attempt_20190523013727_0033_m_000000_29: Committed
19/05/23 01:37:27 INFO Executor: Finished task 0.0 in stage 33.0 (TID 29). 2258 bytes result sent to driver
19/05/23 01:37:27 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 29) in 150 ms on localhost (executor driver) (1/1)
19/05/23 01:37:27 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/05/23 01:37:27 INFO DAGScheduler: ResultStage 33 (json at Spark.scala:57) finished in 0.167 s
19/05/23 01:37:27 INFO DAGScheduler: Job 13 finished: json at Spark.scala:57, took 0.295362 s
19/05/23 01:37:27 INFO FileFormatWriter: Write Job 2c47928a-b06b-47d6-b949-830cc325cea1 committed.
19/05/23 01:37:27 INFO FileFormatWriter: Finished processing stats for write job 2c47928a-b06b-47d6-b949-830cc325cea1.
- Reporting fraudulent transactions per state match (3 seconds, 394 milliseconds)
19/05/23 01:37:27 INFO Spark: ########## Writing DataFrame into /data/reports/masked_dataset
19/05/23 01:37:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/05/23 01:37:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/05/23 01:37:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/05/23 01:37:27 INFO CodeGenerator: Code generated in 26.2833 ms
19/05/23 01:37:27 INFO SparkContext: Starting job: json at Spark.scala:57
19/05/23 01:37:27 INFO DAGScheduler: Registering RDD 100 (json at Spark.scala:57)
19/05/23 01:37:27 INFO DAGScheduler: Got job 14 (json at Spark.scala:57) with 1 output partitions
19/05/23 01:37:27 INFO DAGScheduler: Final stage: ResultStage 35 (json at Spark.scala:57)
19/05/23 01:37:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
19/05/23 01:37:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 34)
19/05/23 01:37:27 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[100] at json at Spark.scala:57), which has no missing parents
19/05/23 01:37:27 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 25.7 KB, free 861.0 MB)
19/05/23 01:37:27 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 11.7 KB, free 861.0 MB)
19/05/23 01:37:27 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on dataengineering:46681 (size: 11.7 KB, free: 910.3 MB)
19/05/23 01:37:27 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[100] at json at Spark.scala:57) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:27 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/05/23 01:37:27 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 7819 bytes)
19/05/23 01:37:27 INFO Executor: Running task 0.0 in stage 34.0 (TID 30)
19/05/23 01:37:27 INFO BlockManager: Found block rdd_15_0 locally
19/05/23 01:37:27 INFO Executor: Finished task 0.0 in stage 34.0 (TID 30). 1686 bytes result sent to driver
19/05/23 01:37:27 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 30) in 220 ms on localhost (executor driver) (1/1)
19/05/23 01:37:27 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/05/23 01:37:27 INFO DAGScheduler: ShuffleMapStage 34 (json at Spark.scala:57) finished in 0.233 s
19/05/23 01:37:27 INFO DAGScheduler: looking for newly runnable stages
19/05/23 01:37:27 INFO DAGScheduler: running: Set()
19/05/23 01:37:27 INFO DAGScheduler: waiting: Set(ResultStage 35)
19/05/23 01:37:27 INFO DAGScheduler: failed: Set()
19/05/23 01:37:27 INFO DAGScheduler: Submitting ResultStage 35 (ShuffledRowRDD[101] at json at Spark.scala:57), which has no missing parents
19/05/23 01:37:27 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 171.3 KB, free 860.9 MB)
19/05/23 01:37:27 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 62.4 KB, free 860.8 MB)
19/05/23 01:37:27 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on dataengineering:46681 (size: 62.4 KB, free: 910.2 MB)
19/05/23 01:37:27 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1161
19/05/23 01:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (ShuffledRowRDD[101] at json at Spark.scala:57) (first 15 tasks are for partitions Vector(0))
19/05/23 01:37:27 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/05/23 01:37:27 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 31, localhost, executor driver, partition 0, ANY, 7246 bytes)
19/05/23 01:37:27 INFO Executor: Running task 0.0 in stage 35.0 (TID 31)
19/05/23 01:37:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
19/05/23 01:37:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/05/23 01:37:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/05/23 01:37:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/05/23 01:37:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
- Creating masked dataset and reporting in JSON (690 milliseconds)
19/05/23 01:37:28 INFO FileOutputCommitter: Saved output of task 'attempt_20190523013727_0035_m_000000_31' to file:/data/reports/masked_dataset/_temporary/0/task_20190523013727_0035_m_000000
19/05/23 01:37:28 INFO SparkHadoopMapRedUtil: attempt_20190523013727_0035_m_000000_31: Committed
19/05/23 01:37:28 INFO Executor: Finished task 0.0 in stage 35.0 (TID 31). 2258 bytes result sent to driver
19/05/23 01:37:28 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 31) in 159 ms on localhost (executor driver) (1/1)
19/05/23 01:37:28 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/05/23 01:37:28 INFO DAGScheduler: ResultStage 35 (json at Spark.scala:57) finished in 0.175 s
19/05/23 01:37:28 INFO DAGScheduler: Job 14 finished: json at Spark.scala:57, took 0.412841 s
19/05/23 01:37:28 INFO FileFormatWriter: Write Job ad8d3b7c-d4f0-4df8-8a72-67cf222e7b28 committed.
19/05/23 01:37:28 INFO FileFormatWriter: Finished processing stats for write job ad8d3b7c-d4f0-4df8-8a72-67cf222e7b28.
19/05/23 01:37:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/05/23 01:37:28 INFO MemoryStore: MemoryStore cleared
19/05/23 01:37:28 INFO BlockManager: BlockManager stopped
19/05/23 01:37:28 INFO BlockManagerMaster: BlockManagerMaster stopped
19/05/23 01:37:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/05/23 01:37:28 INFO SparkContext: Successfully stopped SparkContext
19/05/23 01:37:28 INFO ShutdownHookManager: Shutdown hook called
19/05/23 01:37:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-8e28c0c0-6601-4341-80a0-e15c1569ecaa
Run completed in 33 seconds, 846 milliseconds.
Total number of tests run: 9
Suites: completed 5, aborted 0
Tests: succeeded 9, failed 0, canceled 0, ignored 0, pending 0
All tests passed.

> Task :reportScoverage

BUILD SUCCESSFUL in 2m 21s
7 actionable tasks: 6 executed, 1 up-to-date
2019-05-23 01:37:31,323 INFO exited: app (exit status 0; expected)
2019-05-23 01:37:32,419 WARN received SIGQUIT indicating exit request
2019-05-23 01:37:32,425 INFO waiting for app, mysqld to die
2019-05-23 01:37:33,693 INFO stopped: mysqld (exit status 0)
2019-05-23 01:37:34,667 INFO stopped: app (terminated by SIGTERM)